{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cd9e538e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-04T13:27:56.294589Z",
     "start_time": "2024-08-04T13:27:54.967298Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import math\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "850c1f78",
   "metadata": {},
   "source": [
    "# Arithmetic operations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8571590e",
   "metadata": {},
   "source": [
    "## I. matrix product和inner product"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05e81cce",
   "metadata": {},
   "source": [
    "### I.1 matrix product\n",
    "1. **torch.mm()**: 最基础的矩阵乘法，不做broadcasting\n",
    "   - torch.mv()做matrix vector乘法\n",
    "2. **torch.mul()**: elementwise multiplication with broadcasting\n",
    "   - x.mul(x)相当于x * x\n",
    "3. **torch.matmul()**: 可以用符号@表示，带broadcasting的tensor乘法\n",
    "   - 如果两个参数都是1维，做dot product\n",
    "   - 如果两个参数都是1维，做基础矩阵乘法，等价于torch.mm()\n",
    "   - 如果第1个是matrix，第2个是vector，做matrix vector乘法，等价于torch.mv()\n",
    "   - 如果第1个是vector, 第2个是matrix，按照broadcast机制做矩阵乘法\n",
    "   - 如果其中一个维度高于2维，另一个至少有1维，做batched matrix products\n",
    "     - 另一个2维或以上，这里2维是matrix dims，按照broadcast机制扩展维度，然后与高维的tensor做batched matrix products。\n",
    "       - 如：t1的维度是(j,1,n,m)则(n,m)是matrix dims。t2是(k, m, p),则(m, p)是matrix dims.broadcast在(j,1)和(k)上做，得到$$\n",
    "       (j\\times k\\times n\\times m)\\times(j\\times k\\times m\\times p)=(j\\times k\\times n\\times p)$$\n",
    "     - 另一个1维，\n",
    "       - 如：t1的维度是(j,1,n,m)则(n,m)是matrix dims。t2是(k, m),则(m)是vector dim.broadcast在(j,1)和(k)上做，得到$$\n",
    "       (j\\times k\\times n\\times m)\\times(j\\times k\\times m)=(j\\times k\\times n)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ff41f21a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-04T15:17:05.147777Z",
     "start_time": "2024-08-04T15:17:05.140434Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[[1, 1, 1, 1],\n",
       "           [1, 1, 1, 1]]],\n",
       " \n",
       " \n",
       "         [[[1, 1, 1, 1],\n",
       "           [1, 1, 1, 1]]]], dtype=torch.int32),\n",
       " tensor([[ 0,  1,  2],\n",
       "         [ 3,  4,  5],\n",
       "         [ 6,  7,  8],\n",
       "         [ 9, 10, 11]], dtype=torch.int32))"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.ones(16, dtype=torch.int).view(2, 1, 2, 4)\n",
    "b = torch.arange(12, dtype=torch.int).view(4, 3)\n",
    "a, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2ac3ec03",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-04T15:17:05.808614Z",
     "start_time": "2024-08-04T15:17:05.802375Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 1, 2, 3]),\n",
       " tensor([[[[18, 22, 26],\n",
       "           [18, 22, 26]]],\n",
       " \n",
       " \n",
       "         [[[18, 22, 26],\n",
       "           [18, 22, 26]]]], dtype=torch.int32))"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.matmul(a, b).shape, torch.matmul(a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "49ce1749",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-04T15:17:06.504766Z",
     "start_time": "2024-08-04T15:17:06.498319Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 1, 2]),\n",
       " tensor([[[6, 6]],\n",
       " \n",
       "         [[6, 6]]], dtype=torch.int32))"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = torch.arange(4, dtype=torch.int)\n",
    "torch.matmul(a, c).shape, torch.matmul(a, c)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c0dea56",
   "metadata": {},
   "source": [
    "### I.2 broadcast\n",
    "规则：按照<font color=blue>**last to first**</font>的顺序比较每个dim的值，\n",
    " - 所有dim值相同的话，直接运算；\n",
    " - 不相同的dim上，其中一个operand的dim值是1；\n",
    " - 或者，dimension在其中一个tensor上不存在。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f97213e7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-04T13:27:56.337470Z",
     "start_time": "2024-08-04T13:27:56.332022Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.8827, 0.0272],\n",
      "         [0.2219, 0.5566],\n",
      "         [0.1124, 0.2677]],\n",
      "\n",
      "        [[0.8827, 0.0272],\n",
      "         [0.2219, 0.5566],\n",
      "         [0.1124, 0.2677]]])\n",
      "tensor([[[0.1467, 0.1467],\n",
      "         [0.0363, 0.0363],\n",
      "         [0.1443, 0.1443]],\n",
      "\n",
      "        [[0.1467, 0.1467],\n",
      "         [0.0363, 0.0363],\n",
      "         [0.1443, 0.1443]]])\n",
      "tensor([[[0.0023, 0.0992],\n",
      "         [0.0023, 0.0992],\n",
      "         [0.0023, 0.0992]],\n",
      "\n",
      "        [[0.0023, 0.0992],\n",
      "         [0.0023, 0.0992],\n",
      "         [0.0023, 0.0992]]])\n"
     ]
    }
   ],
   "source": [
    "a =     torch.ones(2, 3, 2)\n",
    "b = a * torch.rand(   3, 2) # 3rd & 2nd dims identical to a, dim 1 absent\n",
    "print(b)\n",
    "\n",
    "c = a * torch.rand(   3, 1) # 3rd dim = 1, 2nd dim identical to a\n",
    "print(c)\n",
    "\n",
    "d = a * torch.rand(   1, 2) # 3rd dim identical to a, 2nd dim = 1\n",
    "print(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "52e7588b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-04T13:27:56.341727Z",
     "start_time": "2024-08-04T13:27:56.338876Z"
    }
   },
   "outputs": [],
   "source": [
    "# 典型错误\n",
    "a =     torch.ones(4, 3, 2)\n",
    "# b = a * torch.rand(4, 3)    # dimensions must match last-to-first\n",
    "# c = a * torch.rand(   2, 3) # both 3rd & 2nd dims different\n",
    "# d = a * torch.rand((0, ))   # can't broadcast with an empty tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b190c5f6",
   "metadata": {},
   "source": [
    "### I.3 inner product\n",
    "#### inner和matrix product执行乘法规则时的区别：\n",
    " - inner的两个矩阵的第二维length要一样:$$(n,k)\\times(m,k)=(n,m)$$\n",
    " - matrix乘法的两个矩阵是第一个的len(dim2)=第二个的len(dim1):$$(n,k)\\times(k,m)=(n,m)$$\n",
    " - 此外，矩阵乘法有broadcast，inner product不涉及broadcast的问题"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0397e696",
   "metadata": {},
   "source": [
    "1. torch.dot()：只支持两个1D tensor的inner product\n",
    "2. torch.inner(): \n",
    "   - 如果参数是两个scalar，做乘法\n",
    "   - 如果参数都不是scalar，那么两个参数的最后一维的length必须相同。\n",
    "     - 如果是两个1D tensor，和dot一样\n",
    "     - 如果参数中至少1个的维度>=2，他们在最后一维上做inner product，<font color=blue>**前面的维度不需要broadcast规则**</font> $$\n",
    "     (j,n,k)\\times(l,m,k)=(j, l, n,m) \\\\\n",
    "     (j,n,k)\\times(l,k)=(j, l, n)\n",
    "     $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "644567de",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-04T15:28:50.406820Z",
     "start_time": "2024-08-04T15:28:50.398034Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0,  1,  2],\n",
       "         [ 3,  4,  5],\n",
       "         [ 6,  7,  8],\n",
       "         [ 9, 10, 11]],\n",
       "\n",
       "        [[12, 13, 14],\n",
       "         [15, 16, 17],\n",
       "         [18, 19, 20],\n",
       "         [21, 22, 23]]], dtype=torch.int32)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.ones(2, 3, dtype=torch.int)\n",
    "b = torch.arange(24, dtype=torch.int).view(2, 4, 3)\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "30362fa3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-04T15:28:51.388910Z",
     "start_time": "2024-08-04T15:28:51.382011Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 2, 4]),\n",
       " tensor([[[ 3, 12, 21, 30],\n",
       "          [39, 48, 57, 66]],\n",
       " \n",
       "         [[ 3, 12, 21, 30],\n",
       "          [39, 48, 57, 66]]], dtype=torch.int32))"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.inner(a, b).shape, torch.inner(a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13f26346",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.inner(a, torch.tensor(2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:231n] *",
   "language": "python",
   "name": "conda-env-231n-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
