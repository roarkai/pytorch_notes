{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "850c1f78",
   "metadata": {},
   "source": [
    "# Arithmetic operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cd9e538e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-09T16:06:58.537463Z",
     "start_time": "2023-10-09T16:06:57.326584Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import math\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "096d2aa2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-09T16:06:58.541969Z",
     "start_time": "2023-10-09T16:06:58.539129Z"
    }
   },
   "outputs": [],
   "source": [
    "x = torch.ones(2, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d107d56c",
   "metadata": {},
   "source": [
    "### matrix product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "92876829",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-09T16:06:58.555354Z",
     "start_time": "2023-10-09T16:06:58.543140Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[3., 3.],\n",
      "        [3., 3.]]) \n",
      " tensor([[3., 3.],\n",
      "        [3., 3.]]) \n",
      " tensor([[3., 3.],\n",
      "        [3., 3.]])\n"
     ]
    }
   ],
   "source": [
    "y1 = x @ x.T\n",
    "y2 = x.matmul(x.T)\n",
    "\n",
    "y3 = torch.zeros((2, 2))\n",
    "torch.matmul(x, x.T, out=y3)\n",
    "print(y1,'\\n', y2,'\\n', y3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8571590e",
   "metadata": {},
   "source": [
    "### element-wise product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2e4cfe16",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-09T16:06:58.560655Z",
     "start_time": "2023-10-09T16:06:58.556920Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.]]) \n",
      " tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.]]) \n",
      " tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "z1 = x * x\n",
    "z2 = x.mul(x)\n",
    "\n",
    "z3 = torch.rand_like(x)\n",
    "torch.mul(x, x, out=z3)\n",
    "print(z1,'\\n', z2,'\\n', z3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79e861ac",
   "metadata": {},
   "source": [
    "### 从单元素tensor中提取元素的value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3191b21c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-09T16:06:58.566139Z",
     "start_time": "2023-10-09T16:06:58.561755Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(6.) <class 'torch.Tensor'> 6.0 <class 'float'>\n"
     ]
    }
   ],
   "source": [
    "y = torch.sum(x) # or y = x.sum()\n",
    "value_y = y.item()\n",
    "print(y, type(y), value_y, type(value_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c0dea56",
   "metadata": {},
   "source": [
    "### broadcast\n",
    "规则：按照**last to first**的顺序比较每个dim的值，\n",
    "所有dim值相同的话，直接运算；\\\n",
    "不相同的dim上，其中一个operand的dim值是0；\\\n",
    "或者，dimension在其中一个tensor上不存在。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f97213e7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-09T16:06:58.573086Z",
     "start_time": "2023-10-09T16:06:58.567233Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.7664, 0.9773],\n",
      "         [0.8280, 0.1166],\n",
      "         [0.1588, 0.2164]],\n",
      "\n",
      "        [[0.7664, 0.9773],\n",
      "         [0.8280, 0.1166],\n",
      "         [0.1588, 0.2164]]])\n",
      "tensor([[[0.5639, 0.5639],\n",
      "         [0.6936, 0.6936],\n",
      "         [0.9699, 0.9699]],\n",
      "\n",
      "        [[0.5639, 0.5639],\n",
      "         [0.6936, 0.6936],\n",
      "         [0.9699, 0.9699]]])\n",
      "tensor([[[0.2750, 0.1434],\n",
      "         [0.2750, 0.1434],\n",
      "         [0.2750, 0.1434]],\n",
      "\n",
      "        [[0.2750, 0.1434],\n",
      "         [0.2750, 0.1434],\n",
      "         [0.2750, 0.1434]]])\n"
     ]
    }
   ],
   "source": [
    "a =     torch.ones(2, 3, 2)\n",
    "b = a * torch.rand(   3, 2) # 3rd & 2nd dims identical to a, dim 1 absent\n",
    "print(b)\n",
    "\n",
    "c = a * torch.rand(   3, 1) # 3rd dim = 1, 2nd dim identical to a\n",
    "print(c)\n",
    "\n",
    "d = a * torch.rand(   1, 2) # 3rd dim identical to a, 2nd dim = 1\n",
    "print(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "52e7588b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-09T16:06:58.576373Z",
     "start_time": "2023-10-09T16:06:58.574183Z"
    }
   },
   "outputs": [],
   "source": [
    "# 典型错误\n",
    "a =     torch.ones(4, 3, 2)\n",
    "# b = a * torch.rand(4, 3)    # dimensions must match last-to-first\n",
    "# c = a * torch.rand(   2, 3) # both 3rd & 2nd dims different\n",
    "# d = a * torch.rand((0, ))   # can't broadcast with an empty tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e4e0443",
   "metadata": {},
   "source": [
    "### in-place ops\n",
    "大多数binary operations都会返回新建的tensor，但很多数学运算也支持in-place operation：\n",
    "1. 用下划线标记，或者用函数提供的out参数\n",
    "2. 虽然in-place操作可以节省存储空间，但求梯度的时候不要用，会丢失weights history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "158e4206",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-09T16:06:58.581489Z",
     "start_time": "2023-10-09T16:06:58.577487Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "原x:\n",
      " tensor([[0.7349, 0.1914, 0.1015],\n",
      "        [0.8505, 0.9423, 0.9360]])\n",
      "in-place add:\n",
      " tensor([[1.7349, 1.1914, 1.1015],\n",
      "        [1.8505, 1.9423, 1.9360]])\n",
      "in-place transpose:\n",
      " tensor([[1.7349, 1.8505],\n",
      "        [1.1914, 1.9423],\n",
      "        [1.1015, 1.9360]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.rand((2, 3))\n",
    "print('原x:\\n', x)\n",
    "x.add_(1)\n",
    "print('in-place add:\\n', x)\n",
    "x.t_()\n",
    "print('in-place transpose:\\n', x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8f83b037",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-09T16:09:56.459667Z",
     "start_time": "2023-10-09T16:09:56.451196Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a:\n",
      " tensor([0.0000, 0.7854, 1.5708, 2.3562])\n",
      "output:\n",
      " tensor([0.0000, 0.7071, 1.0000, 0.7071])\n",
      "a没变：\n",
      " tensor([0.0000, 0.7854, 1.5708, 2.3562])\n",
      "b:\n",
      " tensor([0.0000, 0.7854, 1.5708, 2.3562])\n",
      "output:\n",
      " tensor([0.0000, 0.7071, 1.0000, 0.7071])\n",
      "b改变：\n",
      " tensor([0.0000, 0.7071, 1.0000, 0.7071])\n"
     ]
    }
   ],
   "source": [
    "a = torch.tensor([0, math.pi / 4, math.pi / 2, 3 * math.pi / 4])\n",
    "print('a:\\n', a)\n",
    "print(\"output:\\n\", torch.sin(a)) \n",
    "print(\"a没变：\\n\", a) \n",
    "\n",
    "b = torch.tensor([0, math.pi / 4, math.pi / 2, 3 * math.pi / 4])\n",
    "print('b:\\n', b)\n",
    "print(\"output:\\n\", torch.sin_(b))\n",
    "print(\"b改变：\\n\", b) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6093c151",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-09T16:13:20.147869Z",
     "start_time": "2023-10-09T16:13:20.140107Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0.],\n",
      "        [0., 0.]])\n",
      "tensor([[0.4293, 0.2532],\n",
      "        [0.8134, 0.5592]])\n",
      "tensor([[0.9239, 0.9773],\n",
      "        [0.4088, 0.9971]])\n"
     ]
    }
   ],
   "source": [
    "a = torch.rand(2, 2)\n",
    "b = torch.rand(2, 2)\n",
    "c = torch.zeros(2, 2)\n",
    "old_id = id(c)\n",
    "\n",
    "print(c)\n",
    "d = torch.matmul(a, b, out=c)\n",
    "print(c)                # contents of c have changed\n",
    "\n",
    "assert c is d           # test c & d are same object, not just containing equal values\n",
    "assert id(c) == old_id  # make sure that our new c is the same object as the old one\n",
    "\n",
    "torch.rand(2, 2, out=c) # works for creation too!\n",
    "print(c)                # c has changed again\n",
    "assert id(c) == old_id  # still the same object!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83c9ac7a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-10T01:09:48.583537Z",
     "start_time": "2023-10-10T01:09:48.578891Z"
    }
   },
   "source": [
    "### copy tensor\n",
    "1. assignment只是给等号右边对象新建了一个label，并没有复制新的对象\n",
    "2. 如果要复制，可以用tensor.clone()\n",
    "3. 如果被复制的tensor enabled autograd，那么clone得到的tensor也会enable。如果不希望clone得到的tensor复制原tensor的autograd设置，可以用tensor.detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0ee8a55f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-10T01:15:30.960076Z",
     "start_time": "2023-10-10T01:15:30.956172Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[True, True],\n",
      "        [True, True]])\n",
      "tensor([[1., 1.],\n",
      "        [1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "a = torch.ones(2, 2)\n",
    "b = a.clone()\n",
    "\n",
    "assert b is not a      # 在memory中是不同的object\n",
    "# assert b == a          # 不能这样assert，因为b==a输出的是boolean矩阵，assert只处理单个boolean值\n",
    "print(torch.eq(a, b))  # ...but still with the same contents!\n",
    "\n",
    "a[0][1] = 561          # a changes...\n",
    "print(b)               # ...but b is still all ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f5f8f57d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-10T01:21:08.739647Z",
     "start_time": "2023-10-10T01:21:08.732266Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.6986, 0.0886],\n",
      "        [0.3698, 0.3061]], requires_grad=True)\n",
      "tensor([[0.6986, 0.0886],\n",
      "        [0.3698, 0.3061]], grad_fn=<CloneBackward0>)\n",
      "tensor([[0.6986, 0.0886],\n",
      "        [0.3698, 0.3061]])\n",
      "tensor([[0.6986, 0.0886],\n",
      "        [0.3698, 0.3061]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "a = torch.rand(2, 2, requires_grad=True) # turn on autograd\n",
    "print(a)\n",
    "\n",
    "b = a.clone()\n",
    "print(b)\n",
    "\n",
    "c = a.detach().clone()  # 这里在不改变a的设置的条件下，关闭c的autograd\n",
    "print(c)                # c的autograd关闭\n",
    "print(a)                # a的autograd还是开启状态"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "869c23b3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:231n] *",
   "language": "python",
   "name": "conda-env-231n-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
