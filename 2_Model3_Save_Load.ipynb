{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9cfd3d3b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-06T07:39:24.297012Z",
     "start_time": "2024-08-06T07:39:22.990844Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c6cfe41",
   "metadata": {},
   "source": [
    "# Saving and loading the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c500788",
   "metadata": {},
   "source": [
    "- 主要涉及3个core function：\n",
    "   1. <font color=green>**torch.save()**</font>: 存serialized object to disk.用Python’s pickle utility来实现serialization. 可以用于：Models, tensors, and dictionaries of all kinds of objects\n",
    "   2. <font color=green>**torch.load()**</font>: 用pickle’s unpickling facilities来deserialize pickled object files到memory.\n",
    "   3. <font color=green>**torch.nn.Module.load_state_dict()**</font>: Loads a model’s state dictionary using a deserialized state_dict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "55406fcf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-06T07:39:25.678962Z",
     "start_time": "2024-08-06T07:39:24.299150Z"
    }
   },
   "outputs": [],
   "source": [
    "## 定义一个net\n",
    "net = nn.Sequential(\n",
    "    nn.Linear(3, 5),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(5, 2), \n",
    ")\n",
    "\n",
    "torch.manual_seed(7)\n",
    "x = torch.randn((10, 3), dtype=torch.float)\n",
    "y = torch.empty(10, dtype=torch.long).random_(2)\n",
    "\n",
    "learning_rate = 1e-4\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "opt = torch.optim.SGD(net.parameters(), lr=learning_rate)\n",
    "\n",
    "for ind in range(2000):\n",
    "    y_pred = net(x)\n",
    "    loss = loss_fn(y_pred, y)\n",
    "    opt.zero_grad()\n",
    "    loss.backward()\n",
    "    opt.step()\n",
    "    \n",
    "# 训练后得到的参数\n",
    "# for p in net.named_parameters():\n",
    "#     print(p)\n",
    "\n",
    "## save the module\n",
    "torch.save(net.state_dict(), 'net.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e7dd0c66",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-06T07:39:25.689045Z",
     "start_time": "2024-08-06T07:39:25.680572Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## load the module\n",
    "#  1. 新建一个结构相同的module\n",
    "new_net = nn.Sequential(\n",
    "    nn.Linear(3, 5),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(5, 2), \n",
    ")\n",
    "\n",
    "# 此时new_net的参数是没有训练过的初始化值\n",
    "# for p in new_net.named_parameters():\n",
    "#     print(p)\n",
    "\n",
    "#  2. load state\n",
    "new_net.load_state_dict(torch.load('net.pt', weights_only=True))\n",
    "\n",
    "## load之后，new_net的参数已经更新成了net训练完的参数\n",
    "# for p in new_net.named_parameters():\n",
    "#     print(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad47a97f",
   "metadata": {},
   "source": [
    "## 1. 理解module state和state_dict\n",
    "### 1.1 module的state有以下几种类型：\n",
    "  - <font color=blue>**parameters**</font>: learnable aspects of computation。\n",
    "  - <font color=blue>**buffers**</font>: non-learnable aspects of computation。虽然non-learnable，但仍会影响computation。有两种buffers：\n",
    "    - Persistent buffers: 存在state_dict中。在torch.save和load的时候会被serialized。<font color=orange>比如batchnorm中的running mean和var。</font>\n",
    "    - non-Persistent buffers: 不存在state_dict中。在torch.save和load的时候不会被serialized。\n",
    "- <font color=norange>其中，parameters和persistent buffers存在state_dict中。</font>如果state被存为state_dict的一部分，那么loading a serialized form of the module的时候，它就能被restore。 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ec5290bd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-06T07:39:25.701459Z",
     "start_time": "2024-08-06T07:39:25.690767Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('mean', tensor([-0.1494,  0.1179, -0.3679, -0.1974]))])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(True)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 用register_buffer()将running mean的当前值存到state_dict\n",
    "\n",
    "class RunningMean(nn.Module):\n",
    "    def __init__(self, num_features, momentum=0.9):\n",
    "        super().__init__()\n",
    "        self.momentum = momentum\n",
    "        self.register_buffer('mean', torch.zeros(num_features))\n",
    "        # 此时，self.mean会被存到state_dict中\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # 每次迭代时更新running mean的值\n",
    "        # 作为state_dict的一部分，当loading module的时候会被restore\n",
    "        self.mean = self.momentum * self.mean + (1.0 - self.momentum) * x\n",
    "        return self.mean\n",
    "\n",
    "torch.manual_seed(0)\n",
    "m = RunningMean(4)\n",
    "for _ in range(10):\n",
    "    input = torch.randn(4)\n",
    "    m(input)\n",
    "\n",
    "print(m.state_dict())\n",
    "\n",
    "# Serialized form will contain the 'mean' tensor\n",
    "torch.save(m.state_dict(), 'mean.pt')\n",
    "\n",
    "m_loaded = RunningMean(4)\n",
    "m_loaded.load_state_dict(torch.load('mean.pt', weights_only=False))\n",
    "# 安全考虑，weights_only参数应该设为true，这里要load非weights，所以设False\n",
    "\n",
    "torch.all(m.mean == m_loaded.mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3629e24d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-06T07:39:25.708727Z",
     "start_time": "2024-08-06T07:39:25.702667Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict()\n",
      "tensor(False)\n"
     ]
    }
   ],
   "source": [
    "## 将running mean存为non-Persistent buffers\n",
    "\n",
    "class RunningMean(nn.Module):\n",
    "    def __init__(self, num_features, momentum=0.9):\n",
    "        super().__init__()\n",
    "        self.momentum = momentum\n",
    "        self.register_buffer('mean', torch.zeros(num_features), persistent=False)\n",
    "        # 此时，self.mean不会被存到state_dict中\n",
    "    \n",
    "    def forward(self, x):\n",
    "        self.mean = self.momentum * self.mean + (1.0 - self.momentum) * x\n",
    "        return self.mean\n",
    "\n",
    "torch.manual_seed(0)\n",
    "m2 = RunningMean(4)\n",
    "for _ in range(10):\n",
    "    input = torch.randn(4)\n",
    "    m2(input)\n",
    "\n",
    "print(m2.state_dict()) # 此时输出的state_dict是空的\n",
    "\n",
    "torch.save(m2.state_dict(), 'mean.pt')\n",
    "m2_loaded = RunningMean(4)\n",
    "m2_loaded.load_state_dict(torch.load('mean.pt', weights_only=True))\n",
    "print(torch.all(m2.mean == m2_loaded.mean)) # 输出False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ca6f7b2",
   "metadata": {},
   "source": [
    "#### 一个module的buffers可以用buffers()和named_buffers()来遍历"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "20216c4f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-06T07:39:25.712718Z",
     "start_time": "2024-08-06T07:39:25.709911Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('mean', tensor([-0.1494,  0.1179, -0.3679, -0.1974]))\n"
     ]
    }
   ],
   "source": [
    "for buffer in m2.named_buffers():\n",
    "    print(buffer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f872834",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-21T10:42:48.068015Z",
     "start_time": "2023-10-21T10:42:48.065554Z"
    }
   },
   "source": [
    "#### 两种buffers都受model-wide device/type changes所使用的.to() method影响\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "84ffd956",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-06T07:39:25.885885Z",
     "start_time": "2024-08-06T07:39:25.713941Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RunningMean()"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.to(device='cuda', dtype=torch.float64 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "80cf5f4e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-06T07:39:25.900694Z",
     "start_time": "2024-08-06T07:39:25.887859Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name: param1  -- value: tensor([-0.0404,  0.2881])\n",
      "name: param2  -- value: tensor([-0.0075, -0.9145, -1.0886])\n",
      "name: buffer1  -- value: tensor([ 1.3232,  0.0371, -0.2849, -0.1334])\n",
      "name: param_list.0  -- value: tensor([-0.2666,  0.1894])\n",
      "name: param_list.1  -- value: tensor([-0.2190,  2.0576])\n",
      "name: param_list.2  -- value: tensor([-0.0354,  0.0627])\n",
      "name: param_dict.bar  -- value: tensor([ 0.1753, -0.9315, -1.5055, -0.6610])\n",
      "name: param_dict.foo  -- value: tensor([-0.7663,  1.0993,  2.7565])\n",
      "name: linear.weight  -- value: tensor([[ 0.0197, -0.0610],\n",
      "        [ 0.1431,  0.4496],\n",
      "        [ 0.6698,  0.4491]])\n",
      "name: linear.bias  -- value: tensor([ 0.6713, -0.0511, -0.6352])\n"
     ]
    }
   ],
   "source": [
    "## 一个综合例子\n",
    "class StatefulModule(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # 用nn.Parameter实例化的参数会自动将tensor register为module parameter\n",
    "        self.param1 = nn.Parameter(torch.randn(2))\n",
    "\n",
    "        # 另一种将tensor register为module parameter的方式：用register_parameter() method\n",
    "        self.register_parameter('param2', nn.Parameter(torch.randn(3)))\n",
    "\n",
    "        # 将attribute： \"param3\" 定义为一个parameter，但不做初始化。\n",
    "        # 它的值'None'不会出现在state_dict中    \n",
    "        self.register_parameter('param3', None)\n",
    "\n",
    "        # Registers a list of parameters：没有name\n",
    "        self.param_list = nn.ParameterList([nn.Parameter(torch.randn(2)) for i in range(3)])\n",
    "\n",
    "        # Registers a dictionary of parameters：有name\n",
    "        self.param_dict = nn.ParameterDict({\n",
    "            'foo': nn.Parameter(torch.randn(3)),\n",
    "            'bar': nn.Parameter(torch.randn(4))\n",
    "        })\n",
    "\n",
    "        # Registers a persistent buffer\n",
    "        self.register_buffer('buffer1', torch.randn(4), persistent=True)\n",
    "\n",
    "        # Registers a non-persistent buffer\n",
    "        self.register_buffer('buffer2', torch.randn(5), persistent=False)\n",
    "\n",
    "        # 将attribute：\"buffer3\" 定义为一个buffer，但不做初始化\n",
    "        # 它的值'None'也不会出现在state_dict中    \n",
    "        self.register_buffer('buffer3', None)\n",
    "\n",
    "        # 添加一个submodule就会将其parameters自动register为module的parameters\n",
    "        self.linear = nn.Linear(2, 3)\n",
    "\n",
    "m = StatefulModule()\n",
    "\n",
    "# Save and load state_dict.\n",
    "torch.save(m.state_dict(), 'state.pt')\n",
    "m_loaded = StatefulModule()\n",
    "m_loaded.load_state_dict(torch.load('state.pt', weights_only=True))\n",
    "\n",
    "# state_dict中没有non-persistent buffer和reserved attributes \"param3\"与\"buffer3\"\n",
    "for p,v in m_loaded.state_dict().items():\n",
    "    print('name:', p, ' -- value:', v)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1203cbbf",
   "metadata": {},
   "source": [
    "### 1.2 state_dict\n",
    "1. 所有nn.Module中都定义了**state_dict**。它是一个Python dictionary对象，maps each layer to its parameter tensor\n",
    "2. 只有两类module中的state_dict不为空\n",
    "   1. <font color=blue>**layer modules**</font> with learnable parameters和persistent buffers。\n",
    "      - 比如：\n",
    "        - learnable parameters：conv layer\n",
    "        - persistent buffers：batchnorm中的running mean\n",
    "   2. <font color=blue>**optimizer**</font>中的state_dict存放optimizer的state和超参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8574acba",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-06T07:39:25.910076Z",
     "start_time": "2024-08-06T07:39:25.902445Z"
    }
   },
   "outputs": [],
   "source": [
    "## 例\n",
    "# Define model\n",
    "class TheModelClass(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(TheModelClass, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16 * 5 * 5)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "# Initialize model\n",
    "model = TheModelClass()\n",
    "\n",
    "# Initialize optimizer\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "01beb44d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-06T07:39:25.917499Z",
     "start_time": "2024-08-06T07:39:25.913245Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model's state_dict:\n",
      "conv1.weight \t torch.Size([6, 3, 5, 5])\n",
      "conv1.bias \t torch.Size([6])\n",
      "conv2.weight \t torch.Size([16, 6, 5, 5])\n",
      "conv2.bias \t torch.Size([16])\n",
      "fc1.weight \t torch.Size([120, 400])\n",
      "fc1.bias \t torch.Size([120])\n",
      "fc2.weight \t torch.Size([84, 120])\n",
      "fc2.bias \t torch.Size([84])\n",
      "fc3.weight \t torch.Size([10, 84])\n",
      "fc3.bias \t torch.Size([10])\n",
      "--------------------------------------------------\n",
      "Optimizer's state_dict:\n",
      "state \t {}\n",
      "param_groups \t [{'lr': 0.001, 'momentum': 0.9, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'maximize': False, 'foreach': None, 'differentiable': False, 'fused': None, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]}]\n"
     ]
    }
   ],
   "source": [
    "# model's state_dict：包括weights和bias\n",
    "print(\"Model's state_dict:\")\n",
    "for param_tensor in model.state_dict():\n",
    "    print(param_tensor, \"\\t\", model.state_dict()[param_tensor].size())\n",
    "\n",
    "# 分隔线\n",
    "print('-' * 50)\n",
    "\n",
    "# optimizer's state_dict：包括state和超参数\n",
    "print(\"Optimizer's state_dict:\")\n",
    "for var_name in optimizer.state_dict():\n",
    "    print(var_name, \"\\t\", optimizer.state_dict()[var_name])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "487748e9",
   "metadata": {},
   "source": [
    "## 2. saving & loading Model for Inference\n",
    "### 2.1 save/load state_dict\n",
    "· 建议用这种方式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "aea56ea0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-06T07:39:25.927127Z",
     "start_time": "2024-08-06T07:39:25.918882Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_17169/1731230173.py:7: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(PATH)) # 先用torch.load(PATH)是load整个model\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TheModelClass(\n",
       "  (conv1): Conv2d(3, 6, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (fc1): Linear(in_features=400, out_features=120, bias=True)\n",
       "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
       "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# save\n",
    "PATH = 'rk_models/savedClassModelState.pt'   # 路径的文件名后缀一般取pt或者pth\n",
    "torch.save(model.state_dict(), PATH)\n",
    "\n",
    "# load\n",
    "model = TheModelClass()\n",
    "model.load_state_dict(torch.load(PATH)) # 先用torch.load(PATH)是load整个model\n",
    "model.eval()                            # 一定要切换到evaluation mode"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08fdf0fe",
   "metadata": {},
   "source": [
    "### 2.2 save/load entire model\n",
    "最好不用这种方式，这种方式的缺点：\\\n",
    "the serialized data is bound to the specific classes and the exact directory structure used when the model is saved. The reason for this is because pickle does not save the model class itself. Rather, it saves a path to the file containing the class, which is used during load time. Because of this, your code can break in various ways when used in other projects or after refactors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9ec61fbb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-06T07:39:25.934647Z",
     "start_time": "2024-08-06T07:39:25.928352Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_17169/2499684297.py:6: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model = torch.load(PATH)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TheModelClass(\n",
       "  (conv1): Conv2d(3, 6, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (fc1): Linear(in_features=400, out_features=120, bias=True)\n",
       "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
       "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# save\n",
    "PATH = 'rk_models/savedClassModel.pt'   # 路径的文件名后缀一般取pt或者pth\n",
    "torch.save(model, PATH)\n",
    "\n",
    "# load\n",
    "model = torch.load(PATH)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f115d379",
   "metadata": {},
   "source": [
    "### 2.3 export/load model in transcript format\n",
    "规模化的推理和部署建议用这种方式。因为，此时model可以在python和高性能的c++环境中运行。 you will be able to load the exported model and run inference without defining the model class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d14262a1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-06T07:39:25.983669Z",
     "start_time": "2024-08-06T07:39:25.935778Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RecursiveScriptModule(\n",
       "  original_name=TheModelClass\n",
       "  (conv1): RecursiveScriptModule(original_name=Conv2d)\n",
       "  (pool): RecursiveScriptModule(original_name=MaxPool2d)\n",
       "  (conv2): RecursiveScriptModule(original_name=Conv2d)\n",
       "  (fc1): RecursiveScriptModule(original_name=Linear)\n",
       "  (fc2): RecursiveScriptModule(original_name=Linear)\n",
       "  (fc3): RecursiveScriptModule(original_name=Linear)\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# export:\n",
    "model_scripted = torch.jit.script(model) # Export to TorchScript\n",
    "model_scripted.save('model_scripted.pt') # Save\n",
    "\n",
    "# load:\n",
    "model = torch.jit.load('model_scripted.pt')\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45d5bad5",
   "metadata": {},
   "source": [
    "## 3. saving & loading checkpoint for Inference/Resuming trainning\n",
    "1. 用途，存储阶段性训练信息，用于inference或者以此为起点resume training。此时要保存的内容包括:\n",
    "   1. model的state_dict\n",
    "   2. optimizer的state_dict，因为它包括了buffers and parameters that are updated as the model trains.\n",
    "   3. 当前epoch\n",
    "   4. 最近的training loss\n",
    "   5. 外部的torch.nn.Embedding layers，等等\n",
    "2. 由于保存的内容多，所以存checkpoint的大小比只存state_dict更大，一般2-3倍\n",
    "3. 存储的时候，将这些内容用dictionary的结构存储，一般存为后缀.tar的文件名中\n",
    "4. load的时候，先初始化model和optimizer，然后从dictionary中load需要的信息item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "88eaafb4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-06T07:39:25.991378Z",
     "start_time": "2024-08-06T07:39:25.985122Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (conv1): Conv2d(3, 6, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (fc1): Linear(in_features=400, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16 * 5 * 5)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "net = Net()\n",
    "print(net)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "87ff13b4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-06T07:39:25.995541Z",
     "start_time": "2024-08-06T07:39:25.992749Z"
    }
   },
   "outputs": [],
   "source": [
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
    "EPOCH = 5\n",
    "PATH = \"model.pt\"\n",
    "LOSS = 0.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "412cfde0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-06T07:39:26.000814Z",
     "start_time": "2024-08-06T07:39:25.996943Z"
    }
   },
   "outputs": [],
   "source": [
    "# save\n",
    "torch.save({\n",
    "            'epoch': EPOCH,\n",
    "            'model_state_dict': net.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'loss': LOSS,\n",
    "            }, PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "730d6a99",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-06T07:39:26.010961Z",
     "start_time": "2024-08-06T07:39:26.002837Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_17169/1836435359.py:6: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(PATH)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (conv1): Conv2d(3, 6, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (fc1): Linear(in_features=400, out_features=120, bias=True)\n",
       "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
       "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# init新的model结构\n",
    "model = Net()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "# load\n",
    "checkpoint = torch.load(PATH)\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "epoch = checkpoint['epoch']\n",
    "loss = checkpoint['loss']\n",
    "\n",
    "# 根据后续用途来设置model所处的mode\n",
    "model.eval()\n",
    "# - or -\n",
    "model.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81fe14e6",
   "metadata": {},
   "source": [
    "## 4. saving multiple models in one file\n",
    "和存checkpoint相似"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "75dd273f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-06T07:40:55.449813Z",
     "start_time": "2024-08-06T07:40:55.444551Z"
    }
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "':' expected after dictionary key (1202435455.py, line 7)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[20], line 7\u001b[0;36m\u001b[0m\n\u001b[0;31m    ...\u001b[0m\n\u001b[0m      ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m ':' expected after dictionary key\n"
     ]
    }
   ],
   "source": [
    "# save\n",
    "torch.save({\n",
    "            'modelA_state_dict': modelA.state_dict(),\n",
    "            'modelB_state_dict': modelB.state_dict(),\n",
    "            'optimizerA_state_dict': optimizerA.state_dict(),\n",
    "            'optimizerB_state_dict': optimizerB.state_dict(),\n",
    "            ...\n",
    "            }, PATH)\n",
    "\n",
    "# load\n",
    "modelA = TheModelAClass(*args, **kwargs)\n",
    "modelB = TheModelBClass(*args, **kwargs)\n",
    "optimizerA = TheOptimizerAClass(*args, **kwargs)\n",
    "optimizerB = TheOptimizerBClass(*args, **kwargs)\n",
    "\n",
    "checkpoint = torch.load(PATH)\n",
    "modelA.load_state_dict(checkpoint['modelA_state_dict'])\n",
    "modelB.load_state_dict(checkpoint['modelB_state_dict'])\n",
    "optimizerA.load_state_dict(checkpoint['optimizerA_state_dict'])\n",
    "optimizerB.load_state_dict(checkpoint['optimizerB_state_dict'])\n",
    "\n",
    "modelA.eval()\n",
    "modelB.eval()\n",
    "# - or -\n",
    "modelA.train()\n",
    "modelB.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "938a2b12",
   "metadata": {},
   "source": [
    "## 5. warmstarting model using parameters from another model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dacd511",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-06T07:39:26.018643Z",
     "start_time": "2024-08-06T07:39:26.018632Z"
    }
   },
   "outputs": [],
   "source": [
    "# save\n",
    "torch.save(modelA.state_dict(), PATH)\n",
    "# load\n",
    "modelB = TheModelBClass(*args, **kwargs)\n",
    "modelB.load_state_dict(torch.load(PATH), strict=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc310b78",
   "metadata": {},
   "source": [
    "## 6. saving & loading model across devices\n",
    "1. transfer learning中用得多。可以是loading from a partial state_dict, which is missing some keys,或者loading a state_dict with more keys than the model that you are loading into。这两种情况下都可以设置'strict =False'来ignore non-matching keys.\n",
    "\n",
    "2. 如果想要load parameters from one layer to another, 但有的keys不match, 只要改变被loading的state_dict中的parameter的key name，使他们与model that you are loading into中的key name相match就行"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81eb6c65",
   "metadata": {},
   "source": [
    "### 6.1 save on GPU, load on CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "030ccd3f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-06T07:39:26.019505Z",
     "start_time": "2024-08-06T07:39:26.019496Z"
    }
   },
   "outputs": [],
   "source": [
    "# save\n",
    "torch.save(model.state_dict(), PATH)\n",
    "# load\n",
    "device = torch.device('cpu')\n",
    "model = TheModelClass(*args, **kwargs)\n",
    "\n",
    "model.load_state_dict(torch.load(PATH, map_location=device))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4bf00be",
   "metadata": {},
   "source": [
    "### 6.2 save on GPU, load on GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ac3a879",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-06T07:39:26.020339Z",
     "start_time": "2024-08-06T07:39:26.020331Z"
    }
   },
   "outputs": [],
   "source": [
    "# save\n",
    "torch.save(model.state_dict(), PATH)\n",
    "# load\n",
    "device = torch.device(\"cuda\")\n",
    "model = TheModelClass(*args, **kwargs)\n",
    "\n",
    "model.load_state_dict(torch.load(PATH))\n",
    "model.to(device)\n",
    "# Make sure to call input = input.to(device) on any input tensors that you feed to the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47133e42",
   "metadata": {},
   "source": [
    "### 6.3 save on CPU, load on GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f928733e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-06T07:39:26.021198Z",
     "start_time": "2024-08-06T07:39:26.021190Z"
    }
   },
   "outputs": [],
   "source": [
    "# save\n",
    "torch.save(model.state_dict(), PATH)\n",
    "# load\n",
    "device = torch.device(\"cuda\")\n",
    "model = TheModelClass(*args, **kwargs)\n",
    "\n",
    "model.load_state_dict(torch.load(PATH, map_location=\"cuda:0\"))\n",
    "model.to(device)\n",
    "# Make sure to call input = input.to(device) on any input tensors that you feed to the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90795c29",
   "metadata": {},
   "source": [
    "### 6.4 saving torch.nn.DataParallel Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c765732",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-06T07:39:26.022194Z",
     "start_time": "2024-08-06T07:39:26.022185Z"
    }
   },
   "outputs": [],
   "source": [
    "# save\n",
    "torch.save(model.module.state_dict(), PATH)\n",
    "# load\n",
    "# Load to whatever device you want"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:231n] *",
   "language": "python",
   "name": "conda-env-231n-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
