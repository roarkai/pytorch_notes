{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1151dcc0",
   "metadata": {},
   "source": [
    "# Manipulating tensor shapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "48c18bb1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-10T06:07:24.204069Z",
     "start_time": "2023-10-10T06:07:23.028649Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b06b0d79",
   "metadata": {},
   "source": [
    "## 1. squeeze and unsqueeze"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93d83887",
   "metadata": {},
   "source": [
    "### 1.1 unsqueeze\n",
    "1. pytorch默认是按照batch处理数据，以image为例，默认的input大小是(N, C, H, W)。如果想让model处理单个数据，就要把当个样本的大小从(C, H, W)改成(1, C, H, W)\n",
    "2. 常用于ease broadcast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "114a298f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-10T06:07:24.211134Z",
     "start_time": "2023-10-10T06:07:24.205955Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "增加一个长度为1的维度到新的第0维： torch.Size([1, 3, 226, 226])\n",
      "增加一个长度为1的维度到新的第1维： torch.Size([3, 1, 226, 226])\n"
     ]
    }
   ],
   "source": [
    "# 用tensor.unsqueeze()来增加长度为1的新维度\n",
    "a = torch.rand(3, 226, 226)\n",
    "b = a.unsqueeze(0) # 在第0维增加一个维度\n",
    "print('增加一个长度为1的维度到新的第0维：',b.shape)\n",
    "\n",
    "c = a.unsqueeze(1)\n",
    "print('增加一个长度为1的维度到新的第1维：',c.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "73732b73",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-10T06:07:24.225155Z",
     "start_time": "2023-10-10T06:07:24.212462Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 1])\n",
      "tensor([[[0.6783, 0.6783],\n",
      "         [0.1558, 0.1558],\n",
      "         [0.2602, 0.2602]],\n",
      "\n",
      "        [[0.6783, 0.6783],\n",
      "         [0.1558, 0.1558],\n",
      "         [0.2602, 0.2602]],\n",
      "\n",
      "        [[0.6783, 0.6783],\n",
      "         [0.1558, 0.1558],\n",
      "         [0.2602, 0.2602]],\n",
      "\n",
      "        [[0.6783, 0.6783],\n",
      "         [0.1558, 0.1558],\n",
      "         [0.2602, 0.2602]]])\n"
     ]
    }
   ],
   "source": [
    "# unsqueeze常用于方便broadcast\n",
    "a = torch.ones(4, 3, 2)\n",
    "b = torch.rand(   3)     # a * b不能直接运算\n",
    "c = b.unsqueeze(1)       # change to a 2-dimensional tensor, adding new dim at the end\n",
    "print(c.shape)\n",
    "print(a * c)             # broadcasting works again!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a156d9d",
   "metadata": {},
   "source": [
    "### 1.2 squeeze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "80fd7f6e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-10T06:07:24.230672Z",
     "start_time": "2023-10-10T06:07:24.227100Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 4])\n",
      "torch.Size([2, 1, 4])\n"
     ]
    }
   ],
   "source": [
    "#  用tensor.squeeze()来压缩长度为1的维度(dimensions of extent 1)\n",
    "a = torch.rand(1, 2, 1, 4)\n",
    "b = a.squeeze()   # 压缩所有维度为1的dims\n",
    "c = a.squeeze(0)  # 压缩第0维\n",
    "print(b.shape)\n",
    "print(c.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4d20a70",
   "metadata": {},
   "source": [
    "## 2. reshape\n",
    "1. pyrotch要求'shape'参数必须是tuple of ints。但是当shape是第一个参数的时候，可以用series if integers或者单个integer作为shape的值，但如果shape不是第一个参数，就必须是tuple。\\\n",
    "· 注：在extent of dim为1时，要注意，x=(3)是int，x=(3,)是tuple\n",
    "2. 通常情况下，reshape返回的tensor只是原tensor的一个view，两者指向的是相同的memory location。但实际使用的时候，不要依赖这里的view vs. copy关系，不然容易出错。\\\n",
    "· reshape实际上是打包了两种处理方式的method，当reshape的input tensor和outpu tensor的shape是compatible的时候，它调用的是tensor.view()，此时没有copy发生，当两者的shape不兼容的时候，它调用tensor.contiguous()，这时候就会发生copy。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "693c59dc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-10T06:07:24.238051Z",
     "start_time": "2023-10-10T06:07:24.232013Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tuple, int, tuple)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# x=(3)是int，x=(3,)是tuple\n",
    "x = (1, 2, 3)\n",
    "y = (3)\n",
    "z = (2,)\n",
    "type(x), type(y), type(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2b47b8d4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-10T06:07:24.243638Z",
     "start_time": "2023-10-10T06:07:24.239274Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]) torch.Size([12])\n",
      "torch.Size([12])\n"
     ]
    }
   ],
   "source": [
    "output3d = torch.ones(2, 2, 3)\n",
    "\n",
    "## 用tensor.reshape,这时shape参数是第一个参数\n",
    "input1d = output3d.reshape(12) # 12 = 2 * 2 * 3\n",
    "print(input1d, input1d.shape)\n",
    "\n",
    "## 用torch module的reshape method，这时shape参数不是第一个参数\n",
    "# input1d_2 = torch.reshape(output3d, (12)) # 错,(12)被识别为int12\n",
    "input1d_2 = torch.reshape(output3d, (12,))  # 用(12,)才是tuple\n",
    "print(input1d_2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3c7bde51",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-10T06:07:24.248581Z",
     "start_time": "2023-10-10T06:07:24.244886Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0., 0., 0.],\n",
      "         [0., 0., 0.]],\n",
      "\n",
      "        [[1., 1., 1.],\n",
      "         [1., 1., 1.]]])\n",
      "tensor([0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1.])\n"
     ]
    }
   ],
   "source": [
    "# 通常情况下，reshape返回的tensor与原tensor指向的是相同的memory location\n",
    "output3d[0] = 0\n",
    "print(output3d)\n",
    "print(input1d)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad852509",
   "metadata": {},
   "source": [
    "### reshape在什么时候是view，什么时候不是？\n",
    "1. output tensor的size and stride要与input tensor的size and stride兼容\n",
    "2. 规则：dim in the new tensor要么是原tensor dims的subspace，或者span across original dimensions（doc原文描述不清楚，看案例）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "48a3e51d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-10T06:07:24.254156Z",
     "start_time": "2023-10-10T06:07:24.249708Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "原shape: torch.Size([4, 4])\n",
      "用view改城1维后: torch.Size([16])\n",
      "用view改城2维后: torch.Size([2, 8])\n",
      "改变x后，z也改变:\n",
      " tensor([[ 0,  1,  2,  3,  4,  5,  6,  7],\n",
      "        [ 0,  0,  0,  0, 12, 13, 14, 15]])\n"
     ]
    }
   ],
   "source": [
    "## view前后shape兼容\n",
    "x = torch.arange(16).reshape(4, 4)\n",
    "print(\"原shape:\", x.size())\n",
    "y = x.view(16)\n",
    "print(\"用view改城1维后:\", y.size())\n",
    "z = x.view(-1, 8)  # the size -1 is inferred from other dimensions\n",
    "print(\"用view改城2维后:\", z.size())\n",
    "x[2] = 0\n",
    "print('改变x后，z也改变:\\n',z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bcde42f6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-10T06:07:24.261866Z",
     "start_time": "2023-10-10T06:07:24.255730Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "原shape: \n",
      " tensor([[[[ 0,  1,  2,  3],\n",
      "          [ 4,  5,  6,  7],\n",
      "          [ 8,  9, 10, 11]],\n",
      "\n",
      "         [[12, 13, 14, 15],\n",
      "          [16, 17, 18, 19],\n",
      "          [20, 21, 22, 23]]]])\n",
      "torch.Size([1, 2, 3, 4]) 140126738017120 \n",
      "\n",
      "用transpose交换了2nd和3rd dim: \n",
      " tensor([[[[ 0,  1,  2,  3],\n",
      "          [12, 13, 14, 15]],\n",
      "\n",
      "         [[ 4,  5,  6,  7],\n",
      "          [16, 17, 18, 19]],\n",
      "\n",
      "         [[ 8,  9, 10, 11],\n",
      "          [20, 21, 22, 23]]]])\n",
      "torch.Size([1, 3, 2, 4]) 140126747618864 \n",
      "\n",
      "用view不改变元素在memory中的排序方式: \n",
      " tensor([[[[ 0,  1,  2,  3],\n",
      "          [ 4,  5,  6,  7]],\n",
      "\n",
      "         [[ 8,  9, 10, 11],\n",
      "          [12, 13, 14, 15]],\n",
      "\n",
      "         [[16, 17, 18, 19],\n",
      "          [20, 21, 22, 23]]]])\n",
      "torch.Size([1, 3, 2, 4]) 140126738019200 \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(False, False)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 前后shape不兼容，但是不想做copy的话，用transpose\n",
    "\n",
    "a = torch.arange(24).reshape(1, 2, 3, 4)\n",
    "print(\"原shape:\", '\\n', a)\n",
    "print(a.size(), id(a), '\\n')\n",
    "\n",
    "b = a.transpose(1, 2)  # Swaps 2nd and 3rd dimension\n",
    "print(\"用transpose交换了2nd和3rd dim:\", '\\n', b)\n",
    "print(b.size(), id(b), '\\n')\n",
    "\n",
    "c = a.view(1, 3, 2, 4)  # 不改变tensor layout in memory\n",
    "print(\"用view不改变元素在memory中的排序方式:\", '\\n', c)\n",
    "print(c.size(), id(c), '\\n')\n",
    "\n",
    "# c和b只是shape相同，但是元素值不同\n",
    "torch.equal(b, c), c is a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8e5452e4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-10T06:07:24.267460Z",
     "start_time": "2023-10-10T06:07:24.263663Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[  0,   1,   2,   3],\n",
      "          [  4,   5,   6,   7],\n",
      "          [  8,   9,  10,  11]],\n",
      "\n",
      "         [[ 12,  13,  14,  15],\n",
      "          [ 16,  17,  18,  19],\n",
      "          [100, 100, 100, 100]]]]) \n",
      "\n",
      "tensor([[[[  0,   1,   2,   3],\n",
      "          [ 12,  13,  14,  15]],\n",
      "\n",
      "         [[  4,   5,   6,   7],\n",
      "          [ 16,  17,  18,  19]],\n",
      "\n",
      "         [[  8,   9,  10,  11],\n",
      "          [100, 100, 100, 100]]]]) \n",
      "\n",
      "tensor([[[[  0,   1,   2,   3],\n",
      "          [  4,   5,   6,   7]],\n",
      "\n",
      "         [[  8,   9,  10,  11],\n",
      "          [ 12,  13,  14,  15]],\n",
      "\n",
      "         [[ 16,  17,  18,  19],\n",
      "          [100, 100, 100, 100]]]]) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 改变a中元素值, transpose和view对应的值都会改变\n",
    "a[0][1][2] = 100\n",
    "print(a, '\\n')\n",
    "print(b, '\\n')\n",
    "print(c, '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c52aa3db",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-10T06:07:24.272154Z",
     "start_time": "2023-10-10T06:07:24.268569Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(140126738153600, 140126738153600, True)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = [1, 2, 3, 4, 5, 6]\n",
    "b = a\n",
    "id(a), id(b), b is a"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:231n] *",
   "language": "python",
   "name": "conda-env-231n-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
