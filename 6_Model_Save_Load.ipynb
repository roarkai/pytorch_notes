{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0c6cfe41",
   "metadata": {},
   "source": [
    "# Saving and loading the model\n",
    "· 主要涉及3个core function：\\\n",
    "1. <font color=green>**torch.save()**</font>: 存serialized object to disk.用Python’s pickle utility来实现serialization. 可以用于：Models, tensors, and dictionaries of all kinds of objects\n",
    "2. <font color=green>**torch.load()**</font>: 用pickle’s unpickling facilities来deserialize pickled object files到memory.\n",
    "3. <font color=green>**torch.nn.Module.load_state_dict()**</font>: Loads a model’s parameter dictionary using a deserialized state_dict."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1203cbbf",
   "metadata": {},
   "source": [
    "## 1. state_dict\n",
    "1. **什么是state_dict**：a Python dictionary object that maps each layer to its parameter tensor\n",
    "2. 哪些module中有state_dict：module objects(即models)和Optimizer objects\\\n",
    "· optimizer中的state_dict存放optimizer的state和超参数\n",
    "3. 哪些layers在model的state_dict中有对应的entry：\\\n",
    "(1)有learnable parameters的layers，如：convolutional layers, linear layers, etc.\\\n",
    "(2)registered buffers，如：batchnorm’s running_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8574acba",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-21T14:55:33.757292Z",
     "start_time": "2023-10-21T14:55:33.745546Z"
    }
   },
   "outputs": [],
   "source": [
    "## 例\n",
    "# Define model\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "class TheModelClass(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(TheModelClass, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16 * 5 * 5)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "# Initialize model\n",
    "model = TheModelClass()\n",
    "\n",
    "# Initialize optimizer\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "01beb44d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-21T14:56:33.467105Z",
     "start_time": "2023-10-21T14:56:33.459753Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model's state_dict:\n",
      "conv1.weight \t torch.Size([6, 3, 5, 5])\n",
      "conv1.bias \t torch.Size([6])\n",
      "conv2.weight \t torch.Size([16, 6, 5, 5])\n",
      "conv2.bias \t torch.Size([16])\n",
      "fc1.weight \t torch.Size([120, 400])\n",
      "fc1.bias \t torch.Size([120])\n",
      "fc2.weight \t torch.Size([84, 120])\n",
      "fc2.bias \t torch.Size([84])\n",
      "fc3.weight \t torch.Size([10, 84])\n",
      "fc3.bias \t torch.Size([10])\n",
      "--------------------------------------------------\n",
      "Optimizer's state_dict:\n",
      "state \t {}\n",
      "param_groups \t [{'lr': 0.001, 'momentum': 0.9, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'maximize': False, 'foreach': None, 'differentiable': False, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]}]\n"
     ]
    }
   ],
   "source": [
    "# model's state_dict：包括weights和bias\n",
    "print(\"Model's state_dict:\")\n",
    "for param_tensor in model.state_dict():\n",
    "    print(param_tensor, \"\\t\", model.state_dict()[param_tensor].size())\n",
    "\n",
    "# 分隔线\n",
    "print('-' * 50)\n",
    "\n",
    "# optimizer's state_dict：包括state和超参数\n",
    "print(\"Optimizer's state_dict:\")\n",
    "for var_name in optimizer.state_dict():\n",
    "    print(var_name, \"\\t\", optimizer.state_dict()[var_name])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "487748e9",
   "metadata": {},
   "source": [
    "## 2. saving & loading Model for Inference\n",
    "### 2.1 save/load state_dict\n",
    "· 建议用这种方式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "aea56ea0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-21T15:33:17.682558Z",
     "start_time": "2023-10-21T15:33:17.669015Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TheModelClass(\n",
       "  (conv1): Conv2d(3, 6, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (fc1): Linear(in_features=400, out_features=120, bias=True)\n",
       "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
       "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# save\n",
    "PATH = 'rk_models/savedClassModelState.pt'   # 路径的文件名后缀一般取pt或者pth\n",
    "torch.save(model.state_dict(), PATH)\n",
    "\n",
    "# load\n",
    "model = TheModelClass()\n",
    "model.load_state_dict(torch.load(PATH)) # 先用torch.load(PATH)是load整个model\n",
    "model.eval()                            # 一定要切换到evaluation mode"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08fdf0fe",
   "metadata": {},
   "source": [
    "### 2.2 save/load entire model\n",
    "最好不用这种方式，这种方式的缺点：\\\n",
    "the serialized data is bound to the specific classes and the exact directory structure used when the model is saved. The reason for this is because pickle does not save the model class itself. Rather, it saves a path to the file containing the class, which is used during load time. Because of this, your code can break in various ways when used in other projects or after refactors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9ec61fbb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-21T15:35:33.275587Z",
     "start_time": "2023-10-21T15:35:33.263885Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TheModelClass(\n",
       "  (conv1): Conv2d(3, 6, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (fc1): Linear(in_features=400, out_features=120, bias=True)\n",
       "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
       "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# save\n",
    "PATH = 'rk_models/savedClassModel.pt'   # 路径的文件名后缀一般取pt或者pth\n",
    "torch.save(model, PATH)\n",
    "\n",
    "# load\n",
    "model = torch.load(PATH)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f115d379",
   "metadata": {},
   "source": [
    "### 2.3 export/load model in transcript format\n",
    "规模化的推理和部署建议用这种方式。因为，此时model可以在python和高性能的c++环境中运行。 you will be able to load the exported model and run inference without defining the model class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d14262a1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-21T15:40:53.990331Z",
     "start_time": "2023-10-21T15:40:53.920689Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RecursiveScriptModule(\n",
       "  original_name=TheModelClass\n",
       "  (conv1): RecursiveScriptModule(original_name=Conv2d)\n",
       "  (pool): RecursiveScriptModule(original_name=MaxPool2d)\n",
       "  (conv2): RecursiveScriptModule(original_name=Conv2d)\n",
       "  (fc1): RecursiveScriptModule(original_name=Linear)\n",
       "  (fc2): RecursiveScriptModule(original_name=Linear)\n",
       "  (fc3): RecursiveScriptModule(original_name=Linear)\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# export:\n",
    "model_scripted = torch.jit.script(model) # Export to TorchScript\n",
    "model_scripted.save('model_scripted.pt') # Save\n",
    "\n",
    "# load:\n",
    "model = torch.jit.load('model_scripted.pt')\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45d5bad5",
   "metadata": {},
   "source": [
    "## 3. saving & loading checkpoint for Inference/Resuming trainning\n",
    "1. 此时要保存的内容包括：\\\n",
    "(1)model的state_dict \\\n",
    "(2)optimizer的state_dict，因为它包括了buffers and parameters that are updated as the model trains.\\\n",
    "(3)当前epoch \\\n",
    "(4)最近的training loss \\\n",
    "(5)外部的torch.nn.Embedding layers，等等\n",
    "2. 由于保存的内容多，所以存checkpoint的大小通常比只存model更大，一般2-3倍\n",
    "3. 存储的时候，将不同的这些内容用dictionary的结构存储，一般存为后缀.tar的文件名中\n",
    "4. load的时候，先load model和optimizer，然后根据需要从dictionary中load其他item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88eaafb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save\n",
    "torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'loss': loss,\n",
    "            ...\n",
    "            }, PATH)\n",
    "# load\n",
    "model = TheModelClass(*args, **kwargs)\n",
    "optimizer = TheOptimizerClass(*args, **kwargs)\n",
    "\n",
    "checkpoint = torch.load(PATH)\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "epoch = checkpoint['epoch']\n",
    "loss = checkpoint['loss']\n",
    "\n",
    "model.eval()\n",
    "# - or -\n",
    "model.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81fe14e6",
   "metadata": {},
   "source": [
    "## 4. saving multiple models in one file\n",
    "和存checkpoint相似"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75dd273f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save\n",
    "torch.save({\n",
    "            'modelA_state_dict': modelA.state_dict(),\n",
    "            'modelB_state_dict': modelB.state_dict(),\n",
    "            'optimizerA_state_dict': optimizerA.state_dict(),\n",
    "            'optimizerB_state_dict': optimizerB.state_dict(),\n",
    "            ...\n",
    "            }, PATH)\n",
    "\n",
    "# load\n",
    "modelA = TheModelAClass(*args, **kwargs)\n",
    "modelB = TheModelBClass(*args, **kwargs)\n",
    "optimizerA = TheOptimizerAClass(*args, **kwargs)\n",
    "optimizerB = TheOptimizerBClass(*args, **kwargs)\n",
    "\n",
    "checkpoint = torch.load(PATH)\n",
    "modelA.load_state_dict(checkpoint['modelA_state_dict'])\n",
    "modelB.load_state_dict(checkpoint['modelB_state_dict'])\n",
    "optimizerA.load_state_dict(checkpoint['optimizerA_state_dict'])\n",
    "optimizerB.load_state_dict(checkpoint['optimizerB_state_dict'])\n",
    "\n",
    "modelA.eval()\n",
    "modelB.eval()\n",
    "# - or -\n",
    "modelA.train()\n",
    "modelB.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "938a2b12",
   "metadata": {},
   "source": [
    "## 5. warmstarting model using parameters from another model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dacd511",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save\n",
    "torch.save(modelA.state_dict(), PATH)\n",
    "# load\n",
    "modelB = TheModelBClass(*args, **kwargs)\n",
    "modelB.load_state_dict(torch.load(PATH), strict=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc310b78",
   "metadata": {},
   "source": [
    "## 6. saving & loading model across devices\n",
    "1. transfer learning中用得多。可以是loading from a partial state_dict, which is missing some keys,或者loading a state_dict with more keys than the model that you are loading into。这两种情况下都可以设置'strict =False'来ignore non-matching keys.\n",
    "\n",
    "2. 如果想要load parameters from one layer to another, 但有的keys不match, 只要改变被loading的state_dict中的parameter的key name，使他们与model that you are loading into中的key name相match就行"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81eb6c65",
   "metadata": {},
   "source": [
    "### 6.1 save on GPU, load on CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "030ccd3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save\n",
    "torch.save(model.state_dict(), PATH)\n",
    "# load\n",
    "device = torch.device('cpu')\n",
    "model = TheModelClass(*args, **kwargs)\n",
    "\n",
    "model.load_state_dict(torch.load(PATH, map_location=device))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4bf00be",
   "metadata": {},
   "source": [
    "### 6.2 save on GPU, load on GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ac3a879",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save\n",
    "torch.save(model.state_dict(), PATH)\n",
    "# load\n",
    "device = torch.device(\"cuda\")\n",
    "model = TheModelClass(*args, **kwargs)\n",
    "\n",
    "model.load_state_dict(torch.load(PATH))\n",
    "model.to(device)\n",
    "# Make sure to call input = input.to(device) on any input tensors that you feed to the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47133e42",
   "metadata": {},
   "source": [
    "### 6.3 save on CPU, load on GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f928733e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save\n",
    "torch.save(model.state_dict(), PATH)\n",
    "# load\n",
    "device = torch.device(\"cuda\")\n",
    "model = TheModelClass(*args, **kwargs)\n",
    "\n",
    "model.load_state_dict(torch.load(PATH, map_location=\"cuda:0\"))\n",
    "model.to(device)\n",
    "# Make sure to call input = input.to(device) on any input tensors that you feed to the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90795c29",
   "metadata": {},
   "source": [
    "### 6.4 saving torch.nn.DataParallel Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c765732",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save\n",
    "torch.save(model.module.state_dict(), PATH)\n",
    "# load\n",
    "# Load to whatever device you want"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8dfd560",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "52f6702c",
   "metadata": {},
   "source": [
    "## Saving and loading model weights\n",
    "1. pytorch model可以将weights存储在model的internal state dictionary中。方法是用**torch.save** method，之后weights就会存入**state_dict**\n",
    "2. 如果要加载这些weights，可以先创建一个相同model的实例，然后用**load_stat_dict** method来加载权重参数。\n",
    "3. 由于weights只能用在生成它的相同的网络结构上，所以在保存weights的时候，一般还要保存model structure。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e9519052",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-09T09:42:51.461672Z",
     "start_time": "2023-10-09T09:41:10.233841Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/roark/anaconda3/envs/231n/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/home/roark/anaconda3/envs/231n/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN5torch3jit17parseSchemaOrNameERKNSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEE'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n",
      "Downloading: \"https://download.pytorch.org/models/vgg16-397923af.pth\" to /home/roark/.cache/torch/hub/checkpoints/vgg16-397923af.pth\n",
      "51.8%IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "58.0%IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "64.7%IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "74.7%IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "79.5%IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "84.9%IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "98.7%IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "100.0%\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision.models as models\n",
    "\n",
    "# saving\n",
    "model = models.vgg16(weights='IMAGENET1K_V1')\n",
    "torch.save(model.state_dict(), 'model_weights.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "add56733",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-09T09:42:53.568023Z",
     "start_time": "2023-10-09T09:42:51.464364Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VGG(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): ReLU(inplace=True)\n",
       "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (6): ReLU(inplace=True)\n",
       "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (8): ReLU(inplace=True)\n",
       "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (11): ReLU(inplace=True)\n",
       "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (13): ReLU(inplace=True)\n",
       "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (15): ReLU(inplace=True)\n",
       "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (18): ReLU(inplace=True)\n",
       "    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (20): ReLU(inplace=True)\n",
       "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (22): ReLU(inplace=True)\n",
       "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (25): ReLU(inplace=True)\n",
       "    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (27): ReLU(inplace=True)\n",
       "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (29): ReLU(inplace=True)\n",
       "    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
       "  (classifier): Sequential(\n",
       "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Dropout(p=0.5, inplace=False)\n",
       "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "    (4): ReLU(inplace=True)\n",
       "    (5): Dropout(p=0.5, inplace=False)\n",
       "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# loading\n",
    "model = models.vgg16() # we do not specify ``weights``, i.e. create untrained model\n",
    "model.load_state_dict(torch.load('model_weights.pth'))\n",
    "# 在inference之前，一定要调用eval() method。\n",
    "# 作用是set dropout and Batchnorm layers到evaluation mode\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c2198f34",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-09T10:16:27.842251Z",
     "start_time": "2023-10-09T10:16:26.687500Z"
    }
   },
   "outputs": [],
   "source": [
    "# 保存model\n",
    "torch.save(model, 'model.pth')\n",
    "# load model\n",
    "model = torch.load('model.pth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:231n] *",
   "language": "python",
   "name": "conda-env-231n-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
