{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bdcccce1",
   "metadata": {},
   "source": [
    "# 使用GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f59a78b4",
   "metadata": {},
   "source": [
    "## 1. 单GPU环境\n",
    "1. 默认情况下，tensor是在cpu上创建的，可以用tensor.to()将tensor转移到gpu上，或者直接在gpu上新建tensor\n",
    "2. 一个expression中的运算对象要在同一个device上，cpu和gpu上的数据无法在一个expression中处理\n",
    "3. cpu上的tensor可以跟numpy共享底层的memory location，但gpu上的tensor不行。因为gpu上只能放tensor，不能放numpy数据类型\n",
    "4. 使用device handle，不要直接用device name string来设置tensor的位置。前者更容易在不同的设备环境上运行代码，后者一旦改变硬件环境，当name string变化时，代码就不可用\n",
    "5. 要注意，在cpu和gpu之间做数据的迁移很耗费时间。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "71c1e8b4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-10T02:56:44.342616Z",
     "start_time": "2023-10-10T02:56:43.172451Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "43464b01",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-10T03:07:28.105901Z",
     "start_time": "2023-10-10T03:07:28.049708Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0024, 0.6778],\n",
      "        [0.2441, 0.6812]], device='cuda:0')\n",
      "torch.Size([2, 3]) torch.float32 cpu\n",
      "torch.Size([2, 3]) torch.float32 cuda:0\n"
     ]
    }
   ],
   "source": [
    "## 在gpu上新建tensor\n",
    "x = torch.rand(2, 2, device='cuda')\n",
    "print(x)\n",
    "\n",
    "## 将现有tensor移动到gpu\n",
    "x = torch.ones(2, 3)\n",
    "if torch.cuda.is_available():\n",
    "    y = x.to('cuda')\n",
    "print(x.shape, x.dtype, x.device)\n",
    "print(y.shape, y.dtype, y.device)\n",
    "\n",
    "# mul = tensor * tensor2 # 错，他们一个在cpu上，一个在gpu上"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3ae68e06",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-10T03:07:44.510638Z",
     "start_time": "2023-10-10T03:07:44.502783Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "改变前： tensor([1., 1., 1., 1., 1.]) [1. 1. 1. 1. 1.]\n",
      "改变tensor，numpy对象也变： tensor([3., 3., 3., 3., 3.]) [3. 3. 3. 3. 3.]\n",
      "改变numpy对象后，tensor也变： tensor([5., 5., 5., 5., 5.]) [5. 5. 5. 5. 5.]\n",
      "tensor([5., 5., 5., 5., 5.], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "## cpu上的tensor可以跟numpy共享memory location。改变其中一个的值，另一个也变\n",
    "t = torch.ones(5)\n",
    "n = t.numpy()\n",
    "print(\"改变前：\", t, n)\n",
    "t.add_(2)\n",
    "print(\"改变tensor，numpy对象也变：\", t, n)\n",
    "np.add(n, 2, out=n)\n",
    "print(\"改变numpy对象后，tensor也变：\", t, n)\n",
    "\n",
    "## 但在gpu上无法做numpy类型对象的计算\n",
    "if torch.cuda.is_available():\n",
    "    t = t.to('cuda')\n",
    "#     n = n.to('cuda') # numpy对象不能移到gpu上，因为没有.to method\n",
    "print(t)\n",
    "# n = t.numpy() # 报错：can't convert cuda:0 device type tensor to numpy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "467916cc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-10T03:08:03.261813Z",
     "start_time": "2023-10-10T03:08:03.206813Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n",
      "tensor([[0.6815, 0.0556],\n",
      "        [0.0711, 0.4825]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "## device handle\n",
    "if torch.cuda.is_available():\n",
    "    my_device = torch.device('cuda')\n",
    "else:\n",
    "    my_device = torch.device('cpu')\n",
    "print('Device: {}'.format(my_device))\n",
    "\n",
    "x = torch.rand(2, 2, device=my_device)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eecfc101",
   "metadata": {},
   "source": [
    "## 2. 多GPU环境"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "68ee0f1b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-10T03:04:07.195518Z",
     "start_time": "2023-10-10T03:04:07.169646Z"
    }
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: invalid device ordinal\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m#  移动\u001b[39;00m\n\u001b[1;32m      7\u001b[0m x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mones(\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m3\u001b[39m)\n\u001b[0;32m----> 8\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice1\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m#  直接新建\u001b[39;00m\n\u001b[1;32m     10\u001b[0m x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrand(\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m3\u001b[39m, device\u001b[38;5;241m=\u001b[39mdevice1)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: invalid device ordinal\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
     ]
    }
   ],
   "source": [
    "## 查询gpu数量\n",
    "torch.cuda.device_count()\n",
    "\n",
    "## 如果gpu不止1个，可以指定tensor所在的gpu\n",
    "device0, device1 = 'cuda:0', 'cuda:1'\n",
    "#  移动\n",
    "x = torch.ones(2, 3)\n",
    "x = x.to(device1)\n",
    "#  直接新建\n",
    "x = torch.rand(2, 3, device=device1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:231n] *",
   "language": "python",
   "name": "conda-env-231n-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
