{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "71c1e8b4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-02T13:42:48.363837Z",
     "start_time": "2024-08-02T13:42:47.031629Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5986424",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-02T09:21:36.072443Z",
     "start_time": "2024-08-02T09:21:36.067798Z"
    }
   },
   "source": [
    "# Tensor: creating and attributes\n",
    "1. 新建\n",
    "   - 直接指定初始值和shape，用zeros，ones，<font color=blue>rand生成[0-1)均匀分布</font>\n",
    "   - 别的数据类型list, tuple, numpy转变：torch.tensor([[1, 2],[3, 4]]), torch.from_numpy(np_array)\n",
    "   - 用别的tensor的shape：torch.ones_like(tensor_x), torch.rand_like(tensor_x, dtype=torch.float)\n",
    "2. 属性: shape, dtype, device, layout, memory_format"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "275fd7c5",
   "metadata": {},
   "source": [
    "## 1. 新建Tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "852c024f",
   "metadata": {},
   "source": [
    "### 1.1 指定初始值和shape新建tensor\n",
    "1. ones, zeros, empty等操作和numpy相似\n",
    "   - shape可以是tuple，也可以直接给各个dimension的大小，而不package到tuple中\n",
    "2. rand生成[0-1)均匀分布\n",
    "   - 可以用manual_seed()来设定随机种子"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cfe1a607",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-02T13:51:06.261080Z",
     "start_time": "2024-08-02T13:51:06.253126Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0., 0., 0.],\n",
       "         [0., 0., 0.]]),\n",
       " tensor([[1, 1, 1],\n",
       "         [1, 1, 1]], dtype=torch.int16))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shape = (2, 3)\n",
    "x = torch.zeros(shape)\n",
    "y = torch.ones((2, 3), dtype=torch.int16) # 可以指定数据类型\n",
    "x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9918e75c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-02T13:42:48.385340Z",
     "start_time": "2024-08-02T13:42:48.375922Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0.3126, 0.3791, 0.3087],\n",
       "         [0.0736, 0.4216, 0.0691]]),\n",
       " tensor([[True, True, True],\n",
       "         [True, True, True]]))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# random seed\n",
    "torch.manual_seed(1729)  # 设定随机种子\n",
    "r1 = torch.rand(shape)   # [0, 1)均匀分布\n",
    "r2 = torch.rand(shape)\n",
    "\n",
    "torch.manual_seed(1729)\n",
    "r3 = torch.rand(shape) \n",
    "r1, r3 == r1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efdb18ab",
   "metadata": {},
   "source": [
    "### 1.2 将python list，tuple或numpy array转变成tensor类型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "568797f8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-02T13:42:48.391779Z",
     "start_time": "2024-08-02T13:42:48.387518Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1, 2],\n",
       "         [3, 4]]),\n",
       " torch.int64)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from list\n",
    "data = [[1, 2],[3, 4]]\n",
    "x = torch.tensor(data)\n",
    "x, x.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5225523e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-02T13:42:48.397540Z",
     "start_time": "2024-08-02T13:42:48.393179Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[True, True],\n",
       "        [True, True]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from ndarray\n",
    "a = np.array(data)\n",
    "x_np = torch.tensor(a)\n",
    "y_np = torch.from_numpy(a)\n",
    "x_np == y_np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b049671c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-02T13:42:48.403380Z",
     "start_time": "2024-08-02T13:42:48.398939Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1.0000, 2.0000],\n",
       "         [3.5000, 4.0000]]),\n",
       " torch.float32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from混合类型，会自动做datatype cast\n",
    "data = [[1, 2],(3.5, 4)]\n",
    "x_data = torch.tensor(data)\n",
    "x_data, x_data.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "53f0d1d2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-02T13:42:48.409595Z",
     "start_time": "2024-08-02T13:42:48.404853Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0.2332, 0.4047, 0.2162],\n",
       "         [0.9927, 0.4128, 0.5938]]),\n",
       " array([[0.23321933, 0.40465623, 0.2162376 ],\n",
       "        [0.99269456, 0.41275233, 0.59382254]], dtype=float32))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tensor转变成numpy array\n",
    "tensor_x = torch.rand(2, 3)\n",
    "numpy_x = tensor_x.numpy()\n",
    "tensor_x, numpy_x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b37d938b",
   "metadata": {},
   "source": [
    "### 1.3 用已有tensor的shape和datatype来新建tensor\n",
    "这里要注意数据类型变化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "722853c7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-02T13:42:48.416048Z",
     "start_time": "2024-08-02T13:42:48.411024Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1, 1],\n",
       "         [1, 1]], dtype=torch.int16),\n",
       " tensor([[0.6128, 0.1519],\n",
       "         [0.0453, 0.5035]]))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_ones = torch.ones_like(x_data, dtype=torch.int16)\n",
    "\n",
    "# y_rand = torch.rand_like(y_ones) # Error，x_data原来的value是int，数据类型冲突\n",
    "y_rand = torch.rand_like(y_ones, dtype=torch.float)\n",
    "y_ones, y_rand"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89897159",
   "metadata": {},
   "source": [
    "## 2. tensor的属性\n",
    " - t.shape\n",
    " - t.dtype：新建tensor的默认类型是float32\n",
    " - t.device：存储位置在CPU还是GPU\n",
    " - t.layout: 说明tensor的memory layout，目前是beta功能\n",
    " - t.memory_format: 返回tensor存储的方式。有两种存储方式，用于dense tensor的torch.stride和用于sparse tensor的torch.sparse_coo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16c8afa1",
   "metadata": {},
   "source": [
    "### 2.1 数据shape和类型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a178d58b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-02T13:59:39.671567Z",
     "start_time": "2024-08-02T13:59:39.666087Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True, torch.float32)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 设置数据类型的两种方式\n",
    "a = torch.ones((2, 3), dtype=torch.int16)\n",
    "c = a.to(torch.float32)\n",
    "a.shape == a.size(), c.dtype # size()是method，shape是attribute"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdcccce1",
   "metadata": {},
   "source": [
    "### 2.2 存储位置\n",
    "1. tensor默认在cpu上创建，可以用tensor.to('cuda')将tensor转移到gpu上，或者直接在gpu上新建tensor\n",
    "2. 一个expression中的运算对象要在同一个device上，cpu和gpu上的数据无法在一个expression中处理\n",
    "3. cpu上的tensor可以跟numpy共享底层的memory location，但gpu上的tensor不行。因为gpu上只能放tensor，不能放numpy数据类型\n",
    "4. 可以用context manager在不改变默认device的情况下，临时改变新建tensor的device属性\n",
    "- <font color=red>注，cpu和gpu之间的数据迁移很耗费时间。</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6f471bd6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-02T13:42:48.803324Z",
     "start_time": "2024-08-02T13:42:48.423423Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.3344, 0.2640],\n",
       "        [0.2119, 0.0582]], device='cuda:0')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 在gpu上新建tensor\n",
    "x = torch.rand(2, 2, device='cuda')\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b6f3cc75",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-02T13:42:48.810284Z",
     "start_time": "2024-08-02T13:42:48.805177Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3]) torch.float32 cpu\n",
      "torch.Size([2, 3]) torch.float32 cuda:0\n"
     ]
    }
   ],
   "source": [
    "## 将现有tensor移动到gpu\n",
    "x = torch.ones(2, 3)\n",
    "if torch.cuda.is_available():\n",
    "    y = x.to('cuda')\n",
    "print(x.shape, x.dtype, x.device)\n",
    "print(y.shape, y.dtype, y.device)\n",
    "\n",
    "# mul = tensor * tensor2 # 错，他们一个在cpu上，一个在gpu上"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3ae68e06",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-02T13:42:48.817514Z",
     "start_time": "2024-08-02T13:42:48.811708Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "改变前： tensor([1., 1., 1., 1., 1.]) [1. 1. 1. 1. 1.]\n",
      "改变tensor，numpy对象也变： tensor([3., 3., 3., 3., 3.]) [3. 3. 3. 3. 3.]\n",
      "改变numpy对象后，tensor也变： tensor([5., 5., 5., 5., 5.]) [5. 5. 5. 5. 5.]\n"
     ]
    }
   ],
   "source": [
    "## cpu上的tensor可以跟numpy共享memory location。改变其中一个的值，另一个也变\n",
    "t = torch.ones(5)\n",
    "n = t.numpy()\n",
    "print(\"改变前：\", t, n)\n",
    "t.add_(2)\n",
    "print(\"改变tensor，numpy对象也变：\", t, n)\n",
    "np.add(n, 2, out=n) # 不能用n.add(2)，因为ndarray没有add method\n",
    "print(\"改变numpy对象后，tensor也变：\", t, n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1acaaaf7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-02T13:42:48.823283Z",
     "start_time": "2024-08-02T13:42:48.819478Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([5., 5., 5., 5., 5.], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "## 但在gpu上无法做numpy类型对象的计算\n",
    "if torch.cuda.is_available():\n",
    "    t = t.to('cuda')\n",
    "#     n = n.to('cuda') # numpy对象不能移到gpu上，因为没有.to method\n",
    "print(t)\n",
    "# n = t.numpy() # 报错：can't convert cuda:0 device type tensor to numpy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6bfa7bc5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-02T14:04:59.780915Z",
     "start_time": "2024-08-02T14:04:59.752351Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 默认device不变，临时改变device\n",
    "with torch.device('cuda'):\n",
    "    temp_t = torch.randn(3)\n",
    "temp_t.device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adb01492",
   "metadata": {},
   "source": [
    "### 2.3 layout\n",
    "torch.layout是一个object，它返回tensor存储的方式。有两种存储方式：\n",
    " 1. 用于sparse tensor的torch.sparse_coo.还是beta功能。\n",
    " 2. 用于dense tensor的<font color=blue>**torch.strided**</font>。一般的tensor都是用这种layout类型。每个strided tensor都有一个与之关联的<font color=blue>torch.Storage</font>用于存储tensor的底层data，相当于numpy中的data buffer。而tensor本身就是它的一个View。\n",
    "    - 用t.stride()返回tensor t呈现View的stride信息。\n",
    "    - 返回的stride信息是一个int list，每个int代表对应维度上t从一个element到下一个element中间间隔的stride长度。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a1ae78d7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-02T14:22:31.581818Z",
     "start_time": "2024-08-02T14:22:31.574703Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.strided, (5, 1))"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.tensor([[1, 2, 3, 4, 5], [6, 7, 8, 9, 10]])\n",
    "x.layout, x.stride() # dim1上，第1个到第2个element间隔5个值；dim2上间隔1个值"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbae5e2c",
   "metadata": {},
   "source": [
    "### 2.4 memory_format\n",
    "torch.memory_format是一个object，代表tensor分配的存储格式。可能有4种类型：\n",
    "1. <font color=blue>**torch.contiguous_format**</font>: Tensor分配的是dense non-overlapping memory. Strides represented by values in decreasing order.\n",
    "2. <font color=blue>**torch.channels_last**</font>: Tensor分配的是dense non-overlapping memory. Strides represented by values in strides[0] > strides[2] > strides[3] > strides[1] == 1 aka NHWC order.\n",
    "3. <font color=blue>**torch.channels_last_3d**</font>: Tensor分配的是dense non-overlapping memory. Strides represented by values in strides[0] > strides[2] > strides[3] > strides[4] > strides[1] == 1 aka NDHWC order.\n",
    "4. <font color=blue>**torch.preserve_format**</font>: 用在类似clone等函数中，用于保留input tensor的memory format。\n",
    "   - 如果input tensor分配的是dense non-overlapping memory,则output tensor strides会复制input的strides. \n",
    "   - 否则，output strides用torch.contiguous_format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f71c95ff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:231n] *",
   "language": "python",
   "name": "conda-env-231n-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
