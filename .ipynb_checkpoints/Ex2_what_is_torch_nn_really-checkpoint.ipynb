{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3d8712bf",
   "metadata": {},
   "source": [
    "# Torch.nn\n",
    "torch.nn package中的内容是graph的basic building blocks。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75ba79b3",
   "metadata": {},
   "source": [
    "### 1. preparing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9a9164b7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-12T10:18:48.052886Z",
     "start_time": "2023-10-12T10:18:48.014508Z"
    }
   },
   "outputs": [],
   "source": [
    "## download MNIST dataset\n",
    "\n",
    "from pathlib import Path # python3 standary lib\n",
    "import requests          # used to download dataset\n",
    "\n",
    "DATA_PATH = Path(\"data\")\n",
    "PATH  = DATA_PATH / \"mnist\"\n",
    "\n",
    "PATH.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "URL = \"https://github.com/pytorch/tutorials/raw/main/_static/\"\n",
    "FILENAME = \"mnist.pkl.gz\"\n",
    "\n",
    "if not (PATH / FILENAME).exists():\n",
    "        content = requests.get(URL + FILENAME).content\n",
    "        (PATH / FILENAME).open(\"wb\").write(content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df16a7ac",
   "metadata": {},
   "source": [
    "This dataset is in numpy array format, and has been stored using pickle, a python-specific format for serializing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f3377b82",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-12T10:18:48.909468Z",
     "start_time": "2023-10-12T10:18:48.054343Z"
    }
   },
   "outputs": [],
   "source": [
    "## extract data from original files\n",
    "\n",
    "import pickle\n",
    "import gzip\n",
    "\n",
    "with gzip.open((PATH / FILENAME).as_posix(), \"rb\") as f:\n",
    "        ((x_train, y_train), (x_valid, y_valid), _) = pickle.load(f, encoding=\"latin-1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbcc5e4a",
   "metadata": {},
   "source": [
    "Each image is 28 x 28, and is being stored as a flattened row of length 784 (=28x28). To plot one image, we need to reshape it to 2d first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1f6a9281",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-12T10:18:49.260686Z",
     "start_time": "2023-10-12T10:18:48.911177Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 200x200 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 784)\n"
     ]
    }
   ],
   "source": [
    "## plot a image\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "plt.figure(figsize=(2, 2))\n",
    "plt.imshow(x_train[0].reshape((28, 28)), cmap=\"gray\")\n",
    "plt.show()\n",
    "print(x_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "46236039",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-12T10:18:50.406507Z",
     "start_time": "2023-10-12T10:18:49.262773Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]]) tensor([5, 0, 4,  ..., 8, 4, 8])\n",
      "torch.Size([50000, 784])\n",
      "tensor(0) tensor(9)\n"
     ]
    }
   ],
   "source": [
    "## convert the date from numpy arrays to tensors\n",
    "\n",
    "import torch\n",
    "\n",
    "x_train, y_train, x_val, y_val = map(torch.tensor, \n",
    "                                     (x_train, y_train, x_valid, y_valid))\n",
    "\n",
    "N, C = x_train.shape\n",
    "print(x_train, y_train)\n",
    "print(x_train.shape)\n",
    "print(y_train.min(), y_train.max())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea439541",
   "metadata": {},
   "source": [
    "## 2. construct a NN\n",
    "### 2.1 只用最底层tensor operation\n",
    "<font color=red>**· 完全手写函数**</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8034f472",
   "metadata": {},
   "source": [
    "**step1: 初始化weights and bias**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4338aef1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-12T10:18:50.411197Z",
     "start_time": "2023-10-12T10:18:50.408202Z"
    }
   },
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "weights = torch.randn(784, 10)    # random init\n",
    "weights /= math.sqrt(784)         # Xaiver init\n",
    "weights.requires_grad_()          # init之后再set gradient，因为init不用求梯度\n",
    "bias = torch.zeros(10, requires_grad=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a4ebb5d",
   "metadata": {},
   "source": [
    "**step2: 定义forward function, 用model打包**\\\n",
    "<font color=blue>· tensor调用的function都有对应的grad_fn，能自动构造graph，计算backward</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9a9f623d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-12T10:18:50.422424Z",
     "start_time": "2023-10-12T10:18:50.412502Z"
    }
   },
   "outputs": [],
   "source": [
    "def log_softmax(x):\n",
    "    return x - x.exp().sum(-1).log().unsqueeze(-1) # 'unsqueeze' is for broadcast   \n",
    "\n",
    "def model(x_batch):\n",
    "    return log_softmax(x_batch @ weights + bias)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e226014a",
   "metadata": {},
   "source": [
    "**step3: 定义loss function**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4f243c64",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-12T10:18:50.428182Z",
     "start_time": "2023-10-12T10:18:50.423731Z"
    }
   },
   "outputs": [],
   "source": [
    "def negative_log_likelyhood(input, target):\n",
    "    return -input[range(target.shape[0]), target].mean()\n",
    "\n",
    "loss_func = negative_log_likelyhood"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "303411e2",
   "metadata": {},
   "source": [
    "**step4: 定义accuracy function**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1748d82c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-12T10:18:50.433623Z",
     "start_time": "2023-10-12T10:18:50.429463Z"
    }
   },
   "outputs": [],
   "source": [
    "def accuracy(out, y_batch):\n",
    "    preds = torch.argmax(out, dim=1)\n",
    "    return (preds==y_batch).float().mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94455535",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-12T05:45:30.593113Z",
     "start_time": "2023-10-12T05:45:30.588334Z"
    }
   },
   "source": [
    "#### 一个完整的trainning loop\n",
    "step1: mini-batch data\\\n",
    "step2: forward, make prediction\\\n",
    "step3: loss\\\n",
    "step4: backward\\\n",
    "step5: update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d8ef38d8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-12T10:18:51.111031Z",
     "start_time": "2023-10-12T10:18:50.434916Z"
    }
   },
   "outputs": [],
   "source": [
    "lr = 0.5  # learning rate\n",
    "epochs = 2  # how many epochs to train for\n",
    "batch_size = 64\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    for i in range((N - 1) // batch_size + 1):\n",
    "        start_i = i * batch_size\n",
    "        end_i = start_i + batch_size\n",
    "        x_batch = x_train[start_i:end_i]\n",
    "        y_batch = y_train[start_i:end_i]\n",
    "        pred = model(x_batch)\n",
    "        loss = loss_func(pred, y_batch)\n",
    "\n",
    "        loss.backward()\n",
    "        with torch.no_grad():\n",
    "            weights -= weights.grad * lr\n",
    "            bias -= bias.grad * lr\n",
    "            weights.grad.zero_()\n",
    "            bias.grad.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c6287a78",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-12T10:18:51.117135Z",
     "start_time": "2023-10-12T10:18:51.113716Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0836, grad_fn=<NegBackward0>) tensor(1.)\n"
     ]
    }
   ],
   "source": [
    "print(loss_func(model(x_batch), y_batch), accuracy(model(x_batch), y_batch))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71d24005",
   "metadata": {},
   "source": [
    "### 2.2 用相对底层的nn.functional\n",
    "<font color=red>**· 只用很底层的function构件，只是不用手动实现act和loss func**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c6c08868",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-12T10:18:51.130037Z",
     "start_time": "2023-10-12T10:18:51.118220Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0836, grad_fn=<NllLossBackward0>) tensor(1.)\n"
     ]
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "loss_func = F.cross_entropy # loss function用nn.functional\n",
    "\n",
    "def model(x_batch):\n",
    "    return x_batch @ weights + bias\n",
    "\n",
    "print(loss_func(model(x_batch), y_batch), accuracy(model(x_batch), y_batch))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80169494",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-12T06:22:26.570282Z",
     "start_time": "2023-10-12T06:22:26.557834Z"
    }
   },
   "source": [
    "### 2.3 用nn.Module, nn.Parameter\n",
    "<font color=red>**· 自定义forward函数**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4a909d48",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-12T10:18:51.134859Z",
     "start_time": "2023-10-12T10:18:51.131127Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.2912, grad_fn=<NllLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "from torch import nn\n",
    "class MnistLogistic(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.weights = nn.Parameter(torch.randn(784, 10) / math.sqrt(784))\n",
    "        self.bias = nn.Parameter(torch.zeros(10))\n",
    "        \n",
    "    def forward(self, x_batch):\n",
    "        return x_batch @ self.weights + self.bias\n",
    "\n",
    "model = MnistLogistic()\n",
    "\n",
    "print(loss_func(model(x_batch), y_batch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "01b6794c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-12T10:18:51.600546Z",
     "start_time": "2023-10-12T10:18:51.136127Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0799, grad_fn=<NllLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# run a training loop\n",
    "lr = 0.5\n",
    "epoch = 2\n",
    "\n",
    "def fit(model, epoch, lr):\n",
    "    for epoch in range(epochs):\n",
    "        for i in range((N - 1) // batch_size + 1):\n",
    "            start_i = i * batch_size\n",
    "            end_i = start_i + batch_size\n",
    "            x_batch = x_train[start_i: end_i]\n",
    "            y_batch = y_train[start_i: end_i]\n",
    "            pred = model(x_batch)\n",
    "            loss = loss_func(pred, y_batch)\n",
    "            \n",
    "            loss.backward()\n",
    "            with torch.no_grad():\n",
    "                for p in model.parameters():  # nn.Module中的\n",
    "                    p -= p.grad * lr\n",
    "                model.zero_grad()\n",
    "fit(model, epoch, lr)\n",
    "print(loss_func(model(x_batch), y_batch))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4712d758",
   "metadata": {},
   "source": [
    "### 2.4 在nn.Module中用nn中的layers\n",
    "<font color=red>**· forward直接调用nn自带的layer**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b8118e4b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-12T10:18:51.605336Z",
     "start_time": "2023-10-12T10:18:51.601890Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.3799, grad_fn=<NllLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "class MnistLogistic(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.lin = nn.Linear(784, 10)\n",
    "        \n",
    "    def forward(self, x_batch):\n",
    "        return self.lin(x_batch)\n",
    "\n",
    "model = MnistLogistic()\n",
    "\n",
    "# 一个batch\n",
    "print(loss_func(model(x_batch), y_batch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8b3f5f9b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-12T10:18:52.033451Z",
     "start_time": "2023-10-12T10:18:51.606322Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0819, grad_fn=<NllLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# run a training loop\n",
    "lr = 0.5\n",
    "epoch = 2\n",
    "fit(model, epoch, lr)\n",
    "print(loss_func(model(x_batch), y_batch))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75faf3f6",
   "metadata": {},
   "source": [
    "### 2.5 用torch.optim\n",
    "<font color=red>**· 自动完成gradient update**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dba194df",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-12T10:18:52.469438Z",
     "start_time": "2023-10-12T10:18:52.035336Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.2503, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0814, grad_fn=<NllLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "from torch import optim\n",
    "\n",
    "lr = 0.5\n",
    "epoch = 2\n",
    "\n",
    "model = MnistLogistic()\n",
    "opt = optim.SGD(model.parameters(), lr=lr)\n",
    "\n",
    "# 一个batch\n",
    "print(loss_func(model(x_batch), y_batch))\n",
    "\n",
    "# run a trainning loop\n",
    "for epoch in range(epochs):\n",
    "    for i in range((N - 1) // batch_size + 1):\n",
    "        start_i = i * batch_size\n",
    "        end_i = start_i + batch_size\n",
    "        x_batch = x_train[start_i: end_i]\n",
    "        y_batch = y_train[start_i: end_i]\n",
    "        pred = model(x_batch)\n",
    "        loss = loss_func(pred, y_batch)\n",
    "            \n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        opt.zero_grad()\n",
    "\n",
    "print(loss_func(model(x_batch), y_batch))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9404678d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-12T07:20:17.836445Z",
     "start_time": "2023-10-12T07:20:17.825065Z"
    }
   },
   "source": [
    "### 2.6 用Dataset\n",
    "<font color=red>**· 用TensorDataset来wrapping dataset可以方便的iterate, index, slice a tensor along its first dimension**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0e88c313",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-12T10:18:52.473010Z",
     "start_time": "2023-10-12T10:18:52.470852Z"
    }
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "18b5a8c4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-12T10:18:52.932151Z",
     "start_time": "2023-10-12T10:18:52.474079Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0820, grad_fn=<NllLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# 用TensorDataset来wrap dataset\n",
    "train_ds = TensorDataset(x_train, y_train)\n",
    "\n",
    "# 设置超参数\n",
    "lr = 0.5\n",
    "epoch = 2\n",
    "\n",
    "# 设置模型\n",
    "model = MnistLogistic()\n",
    "opt = optim.SGD(model.parameters(), lr=lr)\n",
    "\n",
    "# run a trainning loop\n",
    "for epoch in range(epochs):\n",
    "    for i in range((N - 1) // batch_size + 1):\n",
    "        start_i = i * batch_size\n",
    "        end_i = start_i + batch_size\n",
    "        x_batch, y_batch = train_ds[start_i: end_i]\n",
    "        pred = model(x_batch)\n",
    "        loss = loss_func(pred, y_batch)\n",
    "            \n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        opt.zero_grad()\n",
    "        \n",
    "print(loss_func(model(x_batch), y_batch))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3887aae",
   "metadata": {},
   "source": [
    "### 2.7 用DataLoader\n",
    "<font color=red>**· 自动获得batches，而不再用data[start_i: end_i]的方式手动提取数据**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3463e2e6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-12T10:18:52.935360Z",
     "start_time": "2023-10-12T10:18:52.933401Z"
    }
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2b7dcf01",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-12T10:18:54.018561Z",
     "start_time": "2023-10-12T10:18:52.936357Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0808, grad_fn=<NllLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# 准备数据\n",
    "train_dset = TensorDataset(x_train, y_train)\n",
    "train_dloader = DataLoader(train_dset, batch_size=batch_size)\n",
    "\n",
    "# 设置超参数\n",
    "lr = 0.5\n",
    "epoch = 2\n",
    "\n",
    "# 设置模型\n",
    "model = MnistLogistic()\n",
    "opt = optim.SGD(model.parameters(), lr=lr)\n",
    "\n",
    "# run a trainning loop\n",
    "for epoch in range(epochs):\n",
    "    for x_batch, y_batch in train_dloader:\n",
    "        pred = model(x_batch)\n",
    "        loss = loss_func(pred, y_batch)\n",
    "            \n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        opt.zero_grad()\n",
    "        \n",
    "print(loss_func(model(x_batch), y_batch))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ecefb00",
   "metadata": {},
   "source": [
    "### 2.8 增加validation\n",
    "<font color=red>**· validation不做shuffle，batchsize可以跟training时不同**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c5c5eb6d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-12T10:18:55.356137Z",
     "start_time": "2023-10-12T10:18:54.019738Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.2978)\n",
      "tensor(0.3086)\n"
     ]
    }
   ],
   "source": [
    "# 准备trainning和validation data\n",
    "train_dset = TensorDataset(x_train, y_train)\n",
    "train_dloader = DataLoader(train_dset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "val_dset = TensorDataset(x_val, y_val)\n",
    "val_dloader = DataLoader(val_dset, batch_size=batch_size*2)\n",
    "\n",
    "# 设置超参数\n",
    "lr = 0.5\n",
    "epoch = 2\n",
    "\n",
    "# 设置模型\n",
    "model = MnistLogistic()\n",
    "opt = optim.SGD(model.parameters(), lr=lr)\n",
    "\n",
    "# run a trainning loop\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    for x_batch, y_batch in train_dloader:\n",
    "        pred = model(x_batch)\n",
    "        loss = loss_func(pred, y_batch)\n",
    "            \n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        opt.zero_grad()\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        valid_loss = sum(loss_func(model(x_batch), y_batch) for x_batch, y_batch in val_dloader)\n",
    "\n",
    "    print(valid_loss / len(val_dloader))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c241164d",
   "metadata": {},
   "source": [
    "### 2.9 自定义简化流程的wrapper\n",
    "<font color=red>**· 简化get_data和fit**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "168a5fb9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-12T10:18:55.360789Z",
     "start_time": "2023-10-12T10:18:55.357811Z"
    }
   },
   "outputs": [],
   "source": [
    "def loss_batch(model, loss_func, xb, yb, opt=None):\n",
    "    loss = loss_func(model(xb), yb)\n",
    "\n",
    "    if opt is not None:\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        opt.zero_grad()\n",
    "\n",
    "    return loss.item(), len(xb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a91182d3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-12T10:18:55.372944Z",
     "start_time": "2023-10-12T10:18:55.361769Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def fit(epochs, model, loss_func, opt, train_dl, valid_dl):\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        for xb, yb in train_dl:\n",
    "            loss_batch(model, loss_func, xb, yb, opt)\n",
    "\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            losses, nums = zip(\n",
    "                *[loss_batch(model, loss_func, xb, yb) for xb, yb in valid_dl]\n",
    "            )\n",
    "        val_loss = np.sum(np.multiply(losses, nums)) / np.sum(nums)\n",
    "\n",
    "        print(epoch, val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "77ea97ec",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-12T10:18:55.378259Z",
     "start_time": "2023-10-12T10:18:55.373935Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_data(train_dset, val_dset, batch_size):\n",
    "    return (\n",
    "        DataLoader(train_dset, batch_size=batch_size, shuffle=True), \n",
    "        DataLoader(val_dset, batch_size=batch_size*2)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2ba2d599",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-12T10:18:56.627968Z",
     "start_time": "2023-10-12T10:18:55.379248Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.34410430512428286\n",
      "1 0.280425764632225\n"
     ]
    }
   ],
   "source": [
    "train_dloader, val_dloader = get_data(train_dset, val_dset, batch_size)\n",
    "model = MnistLogistic()\n",
    "opt = optim.SGD(model.parameters(), lr=lr)\n",
    "fit(epochs, model, loss_func, opt, train_dloader, val_dloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77d14a97",
   "metadata": {},
   "source": [
    "### 2.10 用nn.sequential\n",
    "<font color=red>**· X**</font> \\\n",
    "<font color=blue>**· 后面开始改用CNN模型**</font>: (cnn-relu) * 3 -> average_pooling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bad029c7",
   "metadata": {},
   "source": [
    "#### 没有用nn.sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d91d4b01",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-12T10:19:00.436566Z",
     "start_time": "2023-10-12T10:18:56.629391Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.3638364331483841\n",
      "1 0.2855412976503372\n"
     ]
    }
   ],
   "source": [
    "class MnistCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 16, kernel_size=3, stride=2, padding=1)\n",
    "        self.conv2 = nn.Conv2d(16, 16, kernel_size=3, stride=2, padding=1)\n",
    "        self.conv3 = nn.Conv2d(16, 10, kernel_size=3, stride=2, padding=1)\n",
    "\n",
    "    def forward(self, x_batch):\n",
    "        x_batch = x_batch.view(-1, 1, 28, 28)\n",
    "        x_batch = F.relu(self.conv1(x_batch))\n",
    "        x_batch = F.relu(self.conv2(x_batch))\n",
    "        x_batch = F.relu(self.conv3(x_batch))\n",
    "        x_batch = F.avg_pool2d(x_batch, 4)\n",
    "        return x_batch.view(-1, x_batch.size(1))\n",
    "\n",
    "lr = 0.1\n",
    "\n",
    "model = MnistCNN()\n",
    "opt = optim.SGD(model.parameters(), lr=lr, momentum=0.9)\n",
    "\n",
    "fit(epochs, model, loss_func, opt, train_dloader, val_dloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47c7cb1a",
   "metadata": {},
   "source": [
    "#### 用nn.sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f7a70de5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-12T10:19:00.440678Z",
     "start_time": "2023-10-12T10:19:00.437986Z"
    }
   },
   "outputs": [],
   "source": [
    "## 自定义layer要用nn.Module\n",
    "#  自定义一个起数据预处理作用的view layer\n",
    "class Lambda(nn.Module):\n",
    "    def __init__(self, func):\n",
    "        super().__init__()\n",
    "        self.func = func\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.func(x)\n",
    "    \n",
    "def preprocess_view(x):\n",
    "    return x.view(-1, 1, 28, 28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a74d469b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-12T10:19:04.286494Z",
     "start_time": "2023-10-12T10:19:00.444028Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.324300231051445\n",
      "1 0.22543925904631615\n"
     ]
    }
   ],
   "source": [
    "model = nn.Sequential(\n",
    "    Lambda(preprocess_view), \n",
    "    nn.Conv2d(1, 16, kernel_size=3, stride=2, padding=1), \n",
    "    nn.ReLU(), \n",
    "    nn.Conv2d(16, 16, kernel_size=3, stride=2, padding=1),\n",
    "    nn.ReLU(), \n",
    "    nn.Conv2d(16, 10, kernel_size=3, stride=2, padding=1), \n",
    "    nn.ReLU(),\n",
    "    nn.AvgPool2d(4),\n",
    "    Lambda(lambda x: x.view(x.size(0), -1)),\n",
    ")\n",
    "\n",
    "opt = optim.SGD(model.parameters(), lr=lr, momentum=0.9)\n",
    "\n",
    "fit(epochs, model, loss_func, opt, train_dloader, val_dloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e93af0fa",
   "metadata": {},
   "source": [
    "### 2.11 wrapping DataLoader\n",
    "<font color=red>**· 把数据预处理打包到自定义的DataLoader中，让model可以处理任意长宽的图片**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e5abfdec",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-12T10:19:04.291187Z",
     "start_time": "2023-10-12T10:19:04.287890Z"
    }
   },
   "outputs": [],
   "source": [
    "def preprocess(x, y):\n",
    "    return x.view(-1, 1, 28, 28), y\n",
    "\n",
    "\n",
    "class WrappedDataLoader:\n",
    "    def __init__(self, dl, func):\n",
    "        self.dl = dl\n",
    "        self.func = func\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dl)\n",
    "\n",
    "    def __iter__(self):\n",
    "        for b in self.dl:\n",
    "            yield (self.func(*b))\n",
    "\n",
    "train_dloader, val_dloader = get_data(train_dset, val_dset, batch_size)\n",
    "train_dloader = WrappedDataLoader(train_dloader, preprocess)\n",
    "val_dloader = WrappedDataLoader(val_dloader, preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1ecb16d6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-12T10:19:08.135779Z",
     "start_time": "2023-10-12T10:19:04.292235Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.47235092906951903\n",
      "1 0.3237160750865936\n"
     ]
    }
   ],
   "source": [
    "model = nn.Sequential(\n",
    "    nn.Conv2d(1, 16, kernel_size=3, stride=2, padding=1),\n",
    "    nn.ReLU(),\n",
    "    nn.Conv2d(16, 16, kernel_size=3, stride=2, padding=1),\n",
    "    nn.ReLU(),\n",
    "    nn.Conv2d(16, 10, kernel_size=3, stride=2, padding=1),\n",
    "    nn.ReLU(),\n",
    "    nn.AdaptiveAvgPool2d(1),\n",
    "    Lambda(lambda x: x.view(x.size(0), -1)),\n",
    ")\n",
    "\n",
    "opt = optim.SGD(model.parameters(), lr=lr, momentum=0.9)\n",
    "\n",
    "fit(epochs, model, loss_func, opt, train_dloader, val_dloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7fef08c",
   "metadata": {},
   "source": [
    "### 2.12 用GPU做运算\n",
    "<font color=red>**· X**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3dca8894",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-12T10:19:11.254461Z",
     "start_time": "2023-10-12T10:19:08.137474Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/roark/anaconda3/envs/231n/lib/python3.10/site-packages/torch/nn/modules/conv.py:459: UserWarning: Applied workaround for CuDNN issue, install nvrtc.so (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:80.)\n",
      "  return F.conv2d(input, weight, bias, self.stride,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.26847046795487406\n",
      "1 0.22680688416361808\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    dev = torch.device(\"cuda\") \n",
    "else:\n",
    "    dev = torch.device(\"cpu\")\n",
    "\n",
    "# 数据预处理的时候将tensor移到gpu上\n",
    "def preprocess(x, y):\n",
    "    return x.view(-1, 1, 28, 28).to(dev), y.to(dev)\n",
    "\n",
    "train_dloader, val_dloader = get_data(train_dset, val_dset, batch_size)\n",
    "train_dloader = WrappedDataLoader(train_dloader, preprocess)\n",
    "val_dloader = WrappedDataLoader(val_dloader, preprocess)\n",
    "\n",
    "# 将model定义在gpu上\n",
    "model.to(dev)\n",
    "opt = optim.SGD(model.parameters(), lr=lr, momentum=0.9)\n",
    "\n",
    "fit(epochs, model, loss_func, opt, train_dloader, val_dloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d363020",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 上面warning solution是因为cuda lib的版本兼容性引起的，参见：https://stackoverflow.com/questions/76216778/userwarning-applied-workaround-for-cudnn-issue-install-nvrtc-so"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:231n] *",
   "language": "python",
   "name": "conda-env-231n-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
